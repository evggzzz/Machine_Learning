{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.0 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "fe5656c614ed49ae0d940a02e18a4e79e27ac1a6e7394b387f34db37ee0d3976"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# 9/23 機械学習入門\n",
    "## Cancer_logistic.py\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n 係数ベクトル :  [[ 1.63105786  0.02680711 -0.13246811  0.00767925 -0.05700912 -0.28808934\n  -0.4154465  -0.16434182 -0.11637752 -0.01649632  0.0836485   0.87728009\n   0.45990461 -0.0368494  -0.00660199 -0.07740374 -0.11349572 -0.02470928\n  -0.03548644 -0.00827449  1.87867213 -0.25658351 -0.11398355 -0.03404736\n  -0.10553131 -0.89412801 -1.19568551 -0.3236579  -0.3210757  -0.09083185]]\n 切片 :  [0.31076197]\n\n [ 予測値  :  教師ラベル ]\n[0.00780712 0.99219288] : 1\n[9.99999065e-01 9.34666995e-07] : 0\n[9.99893078e-01 1.06921876e-04] : 0\n[0.04376848 0.95623152] : 1\n[9.99999876e-01 1.24447775e-07] : 0\n[0.00593881 0.99406119] : 1\n[0.34615734 0.65384266] : 0\n[0.00309185 0.99690815] : 1\n[0.00223714 0.99776286] : 1\n[0.00307698 0.99692302] : 1\n[0.00111916 0.99888084] : 1\n[0.00866483 0.99133517] : 1\n[0.63690198 0.36309802] : 0\n[5.66722290e-04 9.99433278e-01] : 1\n[0.99880863 0.00119137] : 0\n[0.00306223 0.99693777] : 1\n[9.99910809e-01 8.91908744e-05] : 0\n[9.99990427e-01 9.57330611e-06] : 0\n[9.99999399e-01 6.00755026e-07] : 0\n[0.06212446 0.93787554] : 1\n[0.03855558 0.96144442] : 1\n[0.22173495 0.77826505] : 0\n[0.01760816 0.98239184] : 1\n[9.99187901e-01 8.12099240e-04] : 0\n[0.006906 0.993094] : 1\n[9.99987518e-01 1.24824891e-05] : 0\n[9.99984153e-01 1.58468947e-05] : 0\n[0.01055487 0.98944513] : 1\n[0.00722705 0.99277295] : 1\n[9.99084200e-01 9.15799717e-04] : 0\n[0.001287 0.998713] : 1\n[9.99626083e-01 3.73916631e-04] : 0\n[1.00000000e+00 2.09977929e-17] : 0\n[0.36723527 0.63276473] : 0\n[9.9999152e-01 8.4800475e-06] : 0\n[0.02673579 0.97326421] : 1\n[0.02391762 0.97608238] : 1\n[9.99994114e-01 5.88592186e-06] : 0\n[9.99982057e-01 1.79433254e-05] : 0\n[0.00363693 0.99636307] : 1\n[0.0033558 0.9966442] : 1\n[0.98282703 0.01717297] : 0\n[0.0023774 0.9976226] : 1\n[0.00305806 0.99694194] : 1\n[0.07187534 0.92812466] : 1\n[0.00448608 0.99551392] : 1\n[0.1206207 0.8793793] : 1\n[0.00477523 0.99522477] : 1\n[0.00232371 0.99767629] : 1\n[0.00958347 0.99041653] : 1\n[0.01850232 0.98149768] : 1\n[9.99999830e-01 1.69758992e-07] : 0\n[2.29701698e-04 9.99770298e-01] : 1\n[0.00128232 0.99871768] : 1\n[5.99434488e-04 9.99400566e-01] : 1\n[1.00000000e+00 4.13827776e-30] : 0\n[5.42153379e-04 9.99457847e-01] : 1\n[9.99982099e-01 1.79009312e-05] : 0\n[0.04210499 0.95789501] : 1\n[0.00244292 0.99755708] : 1\n[0.00764424 0.99235576] : 1\n[1.00000000e+00 1.30390758e-10] : 0\n[0.00203004 0.99796996] : 1\n[0.00365085 0.99634915] : 1\n[0.74264671 0.25735329] : 0\n[0.06043359 0.93956641] : 1\n[9.99999986e-01 1.35288797e-08] : 0\n[0.00656555 0.99343445] : 1\n[0.00142751 0.99857249] : 1\n[1.00000000e+00 3.44455325e-16] : 0\n[0.06357273 0.93642727] : 1\n[0.91764686 0.08235314] : 0\n[0.02311248 0.97688752] : 1\n[0.00106212 0.99893788] : 1\n[0.01095487 0.98904513] : 1\n[3.31866496e-04 9.99668134e-01] : 1\n[9.99996183e-01 3.81652712e-06] : 0\n[0.00468012 0.99531988] : 1\n[0.01281389 0.98718611] : 1\n[0.0011126 0.9988874] : 1\n[0.99827109 0.00172891] : 0\n[3.20034013e-04 9.99679966e-01] : 1\n[0.0041287 0.9958713] : 1\n[9.99996439e-01 3.56132562e-06] : 0\n[0.0127256 0.9872744] : 1\n[9.99993502e-01 6.49799989e-06] : 0\n[0.02645339 0.97354661] : 1\n[0.17781825 0.82218175] : 1\n[0.0028438 0.9971562] : 1\n[0.06188306 0.93811694] : 1\n[0.02577965 0.97422035] : 1\n[0.03367553 0.96632447] : 1\n[5.14984487e-04 9.99485016e-01] : 1\n[9.99999995e-01 5.35689884e-09] : 0\n[1.00000000e+00 2.32575545e-14] : 0\n[0.992692 0.007308] : 0\n[9.99999605e-01 3.95481354e-07] : 0\n[9.99999426e-01 5.74163743e-07] : 0\n[0.01009701 0.98990299] : 1\n[0.07427584 0.92572416] : 1\n[0.12866274 0.87133726] : 1\n[9.99998983e-01 1.01659633e-06] : 0\n[0.00403926 0.99596074] : 1\n[0.06095566 0.93904434] : 1\n[0.0078556 0.9921444] : 1\n[0.00178441 0.99821559] : 1\n[0.01844644 0.98155356] : 1\n[0.01308703 0.98691297] : 1\n[9.99951137e-01 4.88628150e-05] : 0\n[0.00102449 0.99897551] : 1\n[0.10241904 0.89758096] : 1\n[0.99835559 0.00164441] : 0\n[0.00311969 0.99688031] : 1\n[0.99458745 0.00541255] : 0\n[0.00101038 0.99898962] : 1\n[0.00380436 0.99619564] : 1\n[0.00220752 0.99779248] : 1\n[0.0176088 0.9823912] : 1\n[0.38172387 0.61827613] : 1\n[0.01907351 0.98092649] : 1\n[0.02254606 0.97745394] : 1\n[5.85061231e-04 9.99414939e-01] : 1\n[0.00153239 0.99846761] : 1\n[0.01598172 0.98401828] : 1\n[0.03899311 0.96100689] : 1\n[0.07816055 0.92183945] : 1\n[0.58467649 0.41532351] : 1\n[0.03632011 0.96367989] : 1\n[0.0082551 0.9917449] : 1\n[0.40623281 0.59376719] : 0\n[0.65836232 0.34163768] : 1\n[0.00583446 0.99416554] : 1\n[0.00618347 0.99381653] : 1\n[0.9374637 0.0625363] : 0\n[0.04262117 0.95737883] : 1\n[0.03290137 0.96709863] : 1\n[6.07189857e-04 9.99392810e-01] : 1\n[0.99514449 0.00485551] : 0\n[9.99999999e-01 6.27918633e-10] : 0\n[9.99999747e-01 2.53304463e-07] : 0\n[0.0226461 0.9773539] : 1\n[1.00000000e+00 4.23822809e-24] : 0\n[0.03345563 0.96654437] : 1\n[0.00159692 0.99840308] : 1\n[0.01213844 0.98786156] : 1\n[0.01929035 0.98070965] : 1\n[0.19558342 0.80441658] : 1\n[0.02971701 0.97028299] : 1\n[0.20893781 0.79106219] : 1\n[9.99976635e-01 2.33646133e-05] : 0\n[1.00000000e+00 1.20505542e-20] : 0\n[0.96309467 0.03690533] : 0\n[8.44071926e-04 9.99155928e-01] : 1\n[0.00342814 0.99657186] : 1\n[0.00289364 0.99710636] : 1\n[0.00101608 0.99898392] : 1\n[0.33662573 0.66337427] : 1\n[0.18977314 0.81022686] : 1\n[0.16213102 0.83786898] : 1\n[0.00379641 0.99620359] : 1\n[0.00104285 0.99895715] : 1\n[1.41012407e-04 9.99858988e-01] : 1\n[1.00000000e+00 3.84182706e-10] : 0\n[9.99999997e-01 3.27906282e-09] : 0\n[0.00401638 0.99598362] : 1\n[3.04812799e-04 9.99695187e-01] : 1\n[0.03828904 0.96171096] : 1\n[0.97018054 0.02981946] : 0\n[1.95362078e-04 9.99804638e-01] : 1\n[0.01059603 0.98940397] : 1\n[0.15189939 0.84810061] : 1\n[9.99991769e-01 8.23068182e-06] : 0\n[0.00601165 0.99398835] : 1\n[0.01109548 0.98890452] : 1\n[0.0032471 0.9967529] : 1\n[0.66167814 0.33832186] : 1\n[0.99485704 0.00514296] : 0\n[0.60780615 0.39219385] : 0\n[1.00000000e+00 1.26300359e-13] : 0\n[0.00113262 0.99886738] : 0\n[0.71669673 0.28330327] : 0\n[0.47487891 0.52512109] : 0\n[0.01193507 0.98806493] : 1\n[8.49343291e-04 9.99150657e-01] : 1\n[0.02912449 0.97087551] : 1\n[9.99999999e-01 1.33173249e-09] : 0\n[9.99999985e-01 1.45681061e-08] : 0\n[9.99298134e-01 7.01866225e-04] : 0\n[0.01080417 0.98919583] : 1\n[0.99084134 0.00915866] : 0\n[0.21777992 0.78222008] : 0\n[0.03808176 0.96191824] : 1\n[1.00000000e+00 2.63918158e-14] : 0\n[0.00338158 0.99661842] : 1\n[0.01298969 0.98701031] : 1\n[0.00189156 0.99810844] : 1\n[0.01116333 0.98883667] : 1\n[0.00130537 0.99869463] : 1\n[0.0036691 0.9963309] : 1\n[0.08799068 0.91200932] : 1\n[0.00163875 0.99836125] : 1\n[0.99177795 0.00822205] : 0\n[0.96556104 0.03443896] : 0\n[0.6988072 0.3011928] : 0\n[0.0334443 0.9665557] : 1\n[0.14448255 0.85551745] : 1\n[9.99983911e-01 1.60891551e-05] : 0\n[0.09645481 0.90354519] : 0\n[0.72473987 0.27526013] : 0\n[0.05603212 0.94396788] : 1\n[0.99262573 0.00737427] : 0\n[1.00000000e+00 4.45363968e-20] : 0\n[0.00482241 0.99517759] : 1\n[0.0117736 0.9882264] : 1\n[0.00153337 0.99846663] : 1\n[0.00143878 0.99856122] : 1\n[9.99318044e-01 6.81955782e-04] : 0\n[9.99968795e-01 3.12046076e-05] : 0\n[0.91078344 0.08921656] : 0\n[0.00680441 0.99319559] : 1\n[9.99993904e-01 6.09553960e-06] : 0\n[9.99998480e-01 1.51991458e-06] : 0\n[0.01537656 0.98462344] : 1\n[0.99781248 0.00218752] : 0\n[9.99993953e-01 6.04699571e-06] : 0\n[9.99992589e-01 7.41050362e-06] : 0\n[0.97785672 0.02214328] : 0\n[0.98439597 0.01560403] : 0\n[9.99409851e-01 5.90148995e-04] : 0\n[0.18743126 0.81256874] : 1\n[0.00108358 0.99891642] : 1\n[0.17215271 0.82784729] : 1\n[0.00545072 0.99454928] : 1\n[0.00789891 0.99210109] : 1\n[9.99999992e-01 7.81383320e-09] : 0\n[0.00788167 0.99211833] : 1\n[0.00135344 0.99864656] : 1\n[1.00000000e+00 2.87004448e-17] : 0\n[0.00194067 0.99805933] : 1\n[0.00129386 0.99870614] : 1\n[0.0044183 0.9955817] : 1\n[0.88075276 0.11924724] : 0\n[0.98020164 0.01979836] : 0\n[1.00000000e+00 1.13520917e-10] : 0\n[0.2607472 0.7392528] : 1\n[0.00149838 0.99850162] : 1\n[1.0000000e+00 2.2956376e-11] : 0\n[0.01757493 0.98242507] : 1\n[0.0069407 0.9930593] : 1\n[0.12302014 0.87697986] : 1\n[0.00932847 0.99067153] : 1\n[9.99117723e-01 8.82277320e-04] : 0\n[0.56413839 0.43586161] : 0\n[1.00000000e+00 5.03631944e-16] : 0\n[0.0167446 0.9832554] : 1\n[9.99150487e-01 8.49512903e-04] : 0\n[0.1065182 0.8934818] : 1\n[5.30636486e-04 9.99469364e-01] : 1\n[0.01857347 0.98142653] : 1\n[1.00000000e+00 2.30126614e-11] : 0\n[0.0136504 0.9863496] : 1\n[0.96312573 0.03687427] : 0\n[0.00197205 0.99802795] : 1\n[0.99381356 0.00618644] : 0\n[0.44617915 0.55382085] : 1\n[9.99348249e-01 6.51750770e-04] : 0\n[0.00290326 0.99709674] : 1\n[0.9983137 0.0016863] : 0\n[0.46424332 0.53575668] : 0\n[9.99999990e-01 9.60290524e-09] : 0\n[0.01949008 0.98050992] : 1\n[3.72357277e-04 9.99627643e-01] : 1\n[0.01035265 0.98964735] : 1\n[0.99898069 0.00101931] : 0\n[0.99627321 0.00372679] : 0\n[7.97007925e-04 9.99202992e-01] : 1\n[3.26251399e-04 9.99673749e-01] : 1\n[0.07636657 0.92363343] : 1\n[0.04552133 0.95447867] : 1\n[0.01453368 0.98546632] : 1\n[0.89054985 0.10945015] : 0\n[0.00374145 0.99625855] : 0\n[0.27053344 0.72946656] : 0\n[0.00214991 0.99785009] : 1\n[4.65387711e-04 9.99534612e-01] : 1\n\n [ 予測結果 ]\n accuracy  :  0.9508771929824561\n precision :  0.9405405405405406\n recall    :  0.9830508474576272\n f1-score  :  0.9613259668508287\n\n [ 予測結果 ]\n              precision    recall  f1-score   support\n\n           0       0.97      0.90      0.93       108\n           1       0.94      0.98      0.96       177\n\n    accuracy                           0.95       285\n   macro avg       0.96      0.94      0.95       285\nweighted avg       0.95      0.95      0.95       285\n\n\n [ 混同行列 ]\n[[ 97  11]\n [  3 174]]\n"
     ]
    }
   ],
   "source": [
    "# ロジスティック回帰\n",
    "import sys\n",
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix, precision_score, recall_score, f1_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# データのロード\n",
    "cancer = datasets.load_breast_cancer()\n",
    "\n",
    "# 特徴量（30次元）\n",
    "feature_names=cancer.feature_names\n",
    "data = cancer.data\n",
    "\n",
    "# 目的変数( malignant, benign )\n",
    "name = cancer.target_names\n",
    "label = cancer.target #分類問題では正解値として正解ラベルを学習時に与える,二値分類問題では，正例(1)もしくは負例(0)\n",
    "\n",
    "# ホールドアウト法（学習データ，テストデータ）\n",
    "train_data, test_data, train_label, test_label = train_test_split(data, label, test_size=0.5, random_state=None)\n",
    "\n",
    "# ロジスティック回帰 \n",
    "# (ソルバー：記憶制限付き準ニュートン法 L-BFGS)\n",
    "# (ペナルティ項：2ノルム)\n",
    "model = LogisticRegression(C=1.0,penalty='l2',solver='lbfgs',max_iter=100)\n",
    "\n",
    "# 学習\n",
    "model.fit(train_data, train_label)\n",
    "\n",
    "# 予測\n",
    "predict = model.predict(test_data)\n",
    "\n",
    "# 係数と切片\n",
    "print( '\\n 係数ベクトル : ' , model.coef_ )\n",
    "print( ' 切片 : ' , model.intercept_)\n",
    "\n",
    "# 予測値，教師ラベル\n",
    "print( '\\n [ 予測値  :  教師ラベル ]' )\n",
    "predict_proba = model.predict_proba(test_data)\n",
    "for i in range(len(test_label)):\n",
    "    print( predict_proba[i] , ':' , test_label[i] ) #predict_proba[i] = [p(0),p(1)][i]\n",
    "    \n",
    "\n",
    "# 予測結果の表示\n",
    "print( \"\\n [ 予測結果 ]\" )\n",
    "print( ' accuracy  : ' , accuracy_score(test_label, predict) )\n",
    "print( ' precision : ' , precision_score(test_label, predict) )\n",
    "print( ' recall    : ' , recall_score(test_label, predict) )\n",
    "print( ' f1-score  : ' , f1_score(test_label, predict) )\n",
    "\n",
    "print( \"\\n [ 予測結果 ]\" )\n",
    "print( classification_report(test_label, predict) )\n",
    "\n",
    "print( \"\\n [ 混同行列 ]\" )\n",
    "print( confusion_matrix(test_label, predict) )\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[1.799e+01 1.038e+01 1.228e+02 ... 2.654e-01 4.601e-01 1.189e-01]\n [2.057e+01 1.777e+01 1.329e+02 ... 1.860e-01 2.750e-01 8.902e-02]\n [1.969e+01 2.125e+01 1.300e+02 ... 2.430e-01 3.613e-01 8.758e-02]\n ...\n [1.660e+01 2.808e+01 1.083e+02 ... 1.418e-01 2.218e-01 7.820e-02]\n [2.060e+01 2.933e+01 1.401e+02 ... 2.650e-01 4.087e-01 1.240e-01]\n [7.760e+00 2.454e+01 4.792e+01 ... 0.000e+00 2.871e-01 7.039e-02]]\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "569"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "# データのロード\n",
    "cancer = datasets.load_breast_cancer()\n",
    "\n",
    "# 特徴量（30次元）\n",
    "feature_names=cancer.feature_names\n",
    "data = cancer.data\n",
    "\n",
    "# 目的変数( malignant, benign )\n",
    "name = cancer.target_names\n",
    "label = cancer.target\n",
    "#print(cancer.feature_names)\n",
    "print(cancer.data)\n",
    "len(cancer.data)\n",
    "#print(name)"
   ]
  },
  {
   "source": [
    "## logistic_CV.py"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      " fit_time        : [0.07477999 0.0356791  0.03619599 0.03664112 0.04191089]\n score_time      : [0.00328898 0.00317788 0.00240493 0.00232387 0.00252509]\n test_accuracy   : [0.92982456 0.92982456 0.96491228 0.93859649 0.95575221]\n test_precision  : [0.94103194 0.92916806 0.96722973 0.93601737 0.95083056]\n test_recall     : [0.9115624  0.9207337  0.95734127 0.93154762 0.95506372]\n test_f          : [0.92297297 0.92460317 0.96191113 0.93369339 0.95285774]\n"
     ]
    }
   ],
   "source": [
    "# ロジスティック回帰（交叉検証）\n",
    "import sys\n",
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "# データのロード\n",
    "cancer = datasets.load_breast_cancer()\n",
    "\n",
    "# 特徴量（30次元）\n",
    "feature_names=cancer.feature_names\n",
    "data = cancer.data\n",
    "\n",
    "# 目的変数( malignant, benign )\n",
    "name = cancer.target_names\n",
    "label = cancer.target\n",
    "\n",
    "# ロジスティック回帰\n",
    "model = LogisticRegression(C=1.0,penalty='l2',solver='lbfgs',max_iter=100)\n",
    "\n",
    "# 交叉検証\n",
    "score = { \"accuracy\": \"accuracy\",\n",
    "            \"precision\": \"precision_macro\",\n",
    "            \"recall\": \"recall_macro\",\n",
    "            \"f\":\"f1_macro\"\n",
    "            }\n",
    "\n",
    "result = cross_validate(model, data, label, cv=5, scoring=score,)\n",
    "\n",
    "# 結果の表示\n",
    "for i , j in result.items():\n",
    "    print( \" {0:15s} : {1}\".format( i , j ) )"
   ]
  },
  {
   "source": [
    "## logistic_GS.py"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n [ 最良なパラメータ ]\n{'C': 0.2, 'max_iter': 100, 'penalty': 'none', 'solver': 'newton-cg'}\n\n 係数ベクトル :  [[ 5.52904987e+00 -1.59149498e+00  8.03708547e-01 -7.67465823e-02\n  -1.64261464e+01  3.66204844e+01 -2.22085957e+01 -3.43412539e+01\n   8.60696490e+00  7.69871710e+00 -1.58642740e+01 -1.33425114e+00\n  -9.54645170e-01 -9.34909375e-02 -1.42542310e+00  5.92780944e+01\n   4.06252598e+01 -1.03357356e+01  1.70885973e+01  9.55782994e+00\n  -4.11254997e+00  6.67883448e-01 -1.10208873e-01  5.96284645e-04\n  -3.81623953e+01  1.56962300e+01 -1.94389982e+01 -9.17632353e+01\n  -3.17481233e+01  7.29211198e+00]]\n 切片 :  [23.10940642]\n\n [ 予測値  :  教師ラベル ]\n[3.37175429e-04 9.99662825e-01] : 1\n[1.00000000e+00 1.00582191e-70] : 0\n[1.97221580e-04 9.99802778e-01] : 1\n[3.29373981e-08 9.99999967e-01] : 1\n[9.99999827e-01 1.72853863e-07] : 0\n[1.73804829e-05 9.99982620e-01] : 1\n[6.22962992e-09 9.99999994e-01] : 1\n[1.00000000e+00 4.45889628e-15] : 0\n[1.89004520e-04 9.99810995e-01] : 1\n[1.42514297e-06 9.99998575e-01] : 1\n[2.76646964e-08 9.99999972e-01] : 1\n[9.99999998e-01 2.02531968e-09] : 0\n[0.00105142 0.99894858] : 1\n[9.99999960e-01 3.98284554e-08] : 0\n[0.15837644 0.84162356] : 1\n[1.00000000e+00 2.55795695e-24] : 0\n[1.07889823e-08 9.99999989e-01] : 1\n[1.25679388e-08 9.99999987e-01] : 1\n[0.18607862 0.81392138] : 1\n[2.08435467e-04 9.99791565e-01] : 1\n[0.00224109 0.99775891] : 1\n[0.96711682 0.03288318] : 0\n[4.95496977e-11 1.00000000e+00] : 1\n[1.29393008e-05 9.99987061e-01] : 1\n[8.03997032e-06 9.99991960e-01] : 1\n[0.00371343 0.99628657] : 1\n[1.26424865e-07 9.99999874e-01] : 1\n[7.67746530e-07 9.99999232e-01] : 1\n[2.60838304e-07 9.99999739e-01] : 1\n[9.99807160e-01 1.92839573e-04] : 0\n[9.99999999e-01 1.30184574e-09] : 0\n[1.00000000e+00 1.55458493e-12] : 0\n[2.31164839e-07 9.99999769e-01] : 1\n[0.0046368 0.9953632] : 1\n[1.00000000e+00 1.26875259e-15] : 0\n[1.49494529e-04 9.99850505e-01] : 1\n[1.54254609e-10 1.00000000e+00] : 1\n[9.99698233e-01 3.01766718e-04] : 0\n[0.99820236 0.00179764] : 0\n[8.62114824e-11 1.00000000e+00] : 1\n[1.00000000e+00 1.80345461e-23] : 0\n[0.00585509 0.99414491] : 0\n[7.28548333e-11 1.00000000e+00] : 1\n[6.33069157e-05 9.99936693e-01] : 1\n[1.00000000e+00 1.00246484e-13] : 0\n[9.99992963e-01 7.03703481e-06] : 0\n[1.00000000e+00 5.06113307e-27] : 0\n[9.99999689e-01 3.11292922e-07] : 0\n[0.99013168 0.00986832] : 1\n[4.29139991e-04 9.99570860e-01] : 0\n[1.00000000e+00 2.55676051e-11] : 0\n[2.44321740e-06 9.99997557e-01] : 1\n[0.03667163 0.96332837] : 1\n[1.0000000e+00 1.1979642e-22] : 0\n[0.83497724 0.16502276] : 0\n[9.99999997e-01 2.65622746e-09] : 0\n[0.54435679 0.45564321] : 1\n[9.99999715e-01 2.84599511e-07] : 0\n[5.33372026e-05 9.99946663e-01] : 1\n[1.00000000e+00 9.13507839e-15] : 0\n[1.00000000e+00 2.58605071e-30] : 0\n[1.99036756e-08 9.99999980e-01] : 1\n[2.48796539e-10 1.00000000e+00] : 1\n[1.82168058e-10 1.00000000e+00] : 1\n[1.15619767e-06 9.99998844e-01] : 1\n[8.91047047e-09 9.99999991e-01] : 1\n[1.19080857e-07 9.99999881e-01] : 1\n[9.99461648e-01 5.38352020e-04] : 1\n[0.00814146 0.99185854] : 1\n[1.32052432e-06 9.99998679e-01] : 1\n[2.10527711e-07 9.99999789e-01] : 1\n[1.00000000e+00 4.76584528e-15] : 0\n[1.05624398e-11 1.00000000e+00] : 1\n[7.09629112e-06 9.99992904e-01] : 1\n[9.99999972e-01 2.82571373e-08] : 0\n[1.03839569e-06 9.99998962e-01] : 1\n[9.99999972e-01 2.77350187e-08] : 0\n[0.00786081 0.99213919] : 1\n[2.28049579e-10 1.00000000e+00] : 1\n[9.99999856e-01 1.43835887e-07] : 0\n[2.12837505e-06 9.99997872e-01] : 1\n[1.00000000e+00 6.92958659e-14] : 0\n[1.72510682e-05 9.99982749e-01] : 1\n[6.19199270e-09 9.99999994e-01] : 1\n[1.00000000e+00 3.23263985e-17] : 0\n[1.00000000e+00 3.88232804e-44] : 0\n[1.00000000e+00 1.93478209e-11] : 0\n[6.67013555e-10 9.99999999e-01] : 1\n[9.99091402e-01 9.08598353e-04] : 1\n[0.32772318 0.67227682] : 0\n[3.14318493e-04 9.99685682e-01] : 1\n[1.73010681e-05 9.99982699e-01] : 1\n[1.00000000e+00 1.01499983e-35] : 0\n[8.43432682e-05 9.99915657e-01] : 1\n[7.25932980e-09 9.99999993e-01] : 1\n[2.68583524e-06 9.99997314e-01] : 1\n[4.15445234e-09 9.99999996e-01] : 1\n[0.0023521 0.9976479] : 0\n[1.00000000e+00 8.86559398e-18] : 0\n[7.67887631e-09 9.99999992e-01] : 1\n[0.95683372 0.04316628] : 1\n[0.09106687 0.90893313] : 0\n[3.28668675e-07 9.99999671e-01] : 1\n[4.62927804e-08 9.99999954e-01] : 1\n[9.76414061e-10 9.99999999e-01] : 1\n[0.00190797 0.99809203] : 1\n[2.58464583e-09 9.99999997e-01] : 1\n[9.72103065e-10 9.99999999e-01] : 1\n[2.91994738e-06 9.99997080e-01] : 1\n[1.00000000e+00 8.06192636e-20] : 0\n[9.99999995e-01 5.25270588e-09] : 0\n[1.00000000e+00 5.35294052e-15] : 0\n[4.19768846e-06 9.99995802e-01] : 1\n[3.28513239e-09 9.99999997e-01] : 1\n[1.61164002e-05 9.99983884e-01] : 1\n[9.99995903e-01 4.09676560e-06] : 0\n[7.95636446e-10 9.99999999e-01] : 1\n[1.00000000e+00 5.19718759e-13] : 0\n[2.17066738e-07 9.99999783e-01] : 1\n[2.19162665e-06 9.99997808e-01] : 1\n[9.99886040e-01 1.13959719e-04] : 0\n[1.49070184e-06 9.99998509e-01] : 1\n[5.69170933e-10 9.99999999e-01] : 1\n[5.80965387e-08 9.99999942e-01] : 1\n[9.99999601e-01 3.99158535e-07] : 0\n[1.00000000e+00 7.66566735e-14] : 0\n[9.20264653e-09 9.99999991e-01] : 1\n[9.99998876e-01 1.12382520e-06] : 0\n[9.99996728e-01 3.27168952e-06] : 0\n[0.99725147 0.00274853] : 0\n[0.57688107 0.42311893] : 0\n[7.12437291e-08 9.99999929e-01] : 1\n[1.0000000e+00 2.2245719e-19] : 0\n[1.98384578e-04 9.99801615e-01] : 1\n[1.00000000e+00 2.66014061e-10] : 0\n[7.02242092e-07 9.99999298e-01] : 1\n[2.29656294e-11 1.00000000e+00] : 1\n[1.00000000e+00 1.86429446e-18] : 0\n[0.00103691 0.99896309] : 1\n[4.50346551e-08 9.99999955e-01] : 1\n[9.99999998e-01 1.61938356e-09] : 0\n[1.00000000e+00 5.99568663e-20] : 0\n[1.00000000e+00 1.47698096e-24] : 0\n[1.00000000e+00 6.12062979e-31] : 0\n[2.48955853e-05 9.99975104e-01] : 1\n[2.22786792e-05 9.99977721e-01] : 1\n[1.18943845e-07 9.99999881e-01] : 1\n[2.65702438e-09 9.99999997e-01] : 1\n[4.21854806e-05 9.99957815e-01] : 1\n[9.24291045e-07 9.99999076e-01] : 1\n[1.00000000e+00 6.98422578e-25] : 0\n[3.38218342e-12 1.00000000e+00] : 1\n[0.00697937 0.99302063] : 1\n[0.4064254 0.5935746] : 1\n[1.00000000e+00 2.14651564e-17] : 0\n[2.92607690e-07 9.99999707e-01] : 1\n[0.99730664 0.00269336] : 0\n[6.89625220e-08 9.99999931e-01] : 1\n[4.50204723e-05 9.99954980e-01] : 1\n[2.59758868e-05 9.99974024e-01] : 1\n[9.99996686e-01 3.31437048e-06] : 0\n[7.62384100e-09 9.99999992e-01] : 1\n[2.70399481e-09 9.99999997e-01] : 1\n[6.44260378e-09 9.99999994e-01] : 1\n[7.81547937e-10 9.99999999e-01] : 1\n[4.58424465e-07 9.99999542e-01] : 1\n[5.53845192e-10 9.99999999e-01] : 1\n[3.96973847e-05 9.99960303e-01] : 1\n[1.00000000e+00 2.63726214e-18] : 0\n[0.00696893 0.99303107] : 1\n[0.98552569 0.01447431] : 0\n[7.56972485e-10 9.99999999e-01] : 1\n[0.00989953 0.99010047] : 1\n[6.55597534e-06 9.99993444e-01] : 1\n[0.99764646 0.00235354] : 0\n[9.99999996e-01 4.04448568e-09] : 0\n[9.37903311e-10 9.99999999e-01] : 1\n[9.99922900e-01 7.71003677e-05] : 0\n[6.41836806e-10 9.99999999e-01] : 1\n[1.00000000e+00 6.37591798e-22] : 0\n[0.00285039 0.99714961] : 1\n[1.38041178e-08 9.99999986e-01] : 1\n[8.63300764e-10 9.99999999e-01] : 1\n[4.59757999e-07 9.99999540e-01] : 1\n[9.99993875e-01 6.12493447e-06] : 0\n[8.88393169e-08 9.99999911e-01] : 1\n[3.81663109e-04 9.99618337e-01] : 1\n[8.57087734e-11 1.00000000e+00] : 1\n[8.20488122e-11 1.00000000e+00] : 1\n[1.00000000e+00 3.01900457e-18] : 0\n[1.00000000e+00 5.18960943e-22] : 0\n[1.38368872e-09 9.99999999e-01] : 1\n[9.99989596e-01 1.04041259e-05] : 0\n[3.76246767e-09 9.99999996e-01] : 1\n[4.30995799e-04 9.99569004e-01] : 0\n[2.04720485e-09 9.99999998e-01] : 1\n[2.80353651e-09 9.99999997e-01] : 1\n[0.0050396 0.9949604] : 1\n[1.53538249e-09 9.99999998e-01] : 1\n[1.3957388e-07 9.9999986e-01] : 1\n[3.33804475e-08 9.99999967e-01] : 1\n[5.88524374e-07 9.99999411e-01] : 1\n[1.95137357e-06 9.99998049e-01] : 1\n[2.18770949e-05 9.99978123e-01] : 1\n[3.63669095e-11 1.00000000e+00] : 1\n[1.40821030e-07 9.99999859e-01] : 1\n[1.53712809e-06 9.99998463e-01] : 1\n[1.00164151e-08 9.99999990e-01] : 1\n[1.10661791e-07 9.99999889e-01] : 1\n[0.27166992 0.72833008] : 1\n[4.70256238e-05 9.99952974e-01] : 1\n[8.62141289e-07 9.99999138e-01] : 1\n[0.00185852 0.99814148] : 0\n[2.03903561e-12 1.00000000e+00] : 1\n[1.0000000e+00 1.3717514e-30] : 0\n[6.12467853e-05 9.99938753e-01] : 1\n[3.32955885e-12 1.00000000e+00] : 1\n[1.00000000e+00 2.63109513e-44] : 0\n[2.41174093e-07 9.99999759e-01] : 1\n[1.00000000e+00 1.69689767e-13] : 0\n[2.34729569e-10 1.00000000e+00] : 1\n[9.39544422e-06 9.99990605e-01] : 1\n[1.00000000e+00 6.42426166e-45] : 0\n[1.00000000e+00 2.57663591e-19] : 0\n[1.00000000e+00 1.14963564e-31] : 0\n[9.78314529e-04 9.99021685e-01] : 1\n[5.16316992e-06 9.99994837e-01] : 1\n[2.59756629e-06 9.99997402e-01] : 1\n[3.69173778e-06 9.99996308e-01] : 1\n[0.06897528 0.93102472] : 0\n[1.22251431e-09 9.99999999e-01] : 1\n[8.57123705e-10 9.99999999e-01] : 1\n[0.99770997 0.00229003] : 0\n[1.13005338e-04 9.99886995e-01] : 1\n[0.0012934 0.9987066] : 1\n[3.43156147e-08 9.99999966e-01] : 1\n[9.99894542e-01 1.05457856e-04] : 0\n[6.30878960e-07 9.99999369e-01] : 1\n[0.63719768 0.36280232] : 0\n[0.86228275 0.13771725] : 0\n[1.14384738e-08 9.99999989e-01] : 1\n[1.00000000e+00 2.50304762e-15] : 0\n[0.0065969 0.9934031] : 1\n[2.57349697e-13 1.00000000e+00] : 1\n[1.06971099e-10 1.00000000e+00] : 1\n[1.97259986e-10 1.00000000e+00] : 1\n[2.46953505e-06 9.99997530e-01] : 1\n[1.00000000e+00 6.53860246e-18] : 0\n[9.99995970e-01 4.03010339e-06] : 0\n[3.13284954e-11 1.00000000e+00] : 1\n[1.00000000e+00 3.40667948e-10] : 0\n[1.00000000e+00 4.55392367e-16] : 0\n[1.00000000e+00 6.62199283e-11] : 0\n[5.18384069e-08 9.99999948e-01] : 1\n[9.99999385e-01 6.14809369e-07] : 0\n[3.10483959e-07 9.99999690e-01] : 1\n[1.0000000e+00 2.3853507e-34] : 0\n[6.37257928e-07 9.99999363e-01] : 1\n[5.50805016e-08 9.99999945e-01] : 1\n[4.86496043e-07 9.99999514e-01] : 1\n[1.00000000e+00 3.81867132e-11] : 0\n[6.21011464e-10 9.99999999e-01] : 1\n[8.80623183e-08 9.99999912e-01] : 1\n[1.00000000e+00 4.10705833e-31] : 0\n[9.99844107e-01 1.55893030e-04] : 0\n[1.00000000e+00 5.39676798e-22] : 0\n[0.19443049 0.80556951] : 0\n[0.25693094 0.74306906] : 1\n[1.00000000e+00 3.50637961e-14] : 0\n[1.08844045e-11 1.00000000e+00] : 1\n[9.99999895e-01 1.04936033e-07] : 0\n[4.96491737e-13 1.00000000e+00] : 1\n[0.03509024 0.96490976] : 0\n[3.69758289e-07 9.99999630e-01] : 1\n[9.07171678e-04 9.99092828e-01] : 0\n[4.6032067e-12 1.0000000e+00] : 1\n[6.10013196e-09 9.99999994e-01] : 1\n[1.84583968e-05 9.99981542e-01] : 1\n[3.66798969e-09 9.99999996e-01] : 1\n[3.57213051e-04 9.99642787e-01] : 1\n[2.30258732e-05 9.99976974e-01] : 1\n[1.00000000e+00 8.03641493e-23] : 0\n[9.99999995e-01 4.81499761e-09] : 0\n[5.10418374e-11 1.00000000e+00] : 1\n[5.14184251e-11 1.00000000e+00] : 1\n\n [ 予測結果 ]\n accuracy  :  0.9438596491228071\n precision :  0.9408602150537635\n recall    :  0.9722222222222222\n f1-score  :  0.9562841530054644\n\n [ 予測結果 ]\n              precision    recall  f1-score   support\n\n           0       0.95      0.90      0.92       105\n           1       0.94      0.97      0.96       180\n\n    accuracy                           0.94       285\n   macro avg       0.95      0.93      0.94       285\nweighted avg       0.94      0.94      0.94       285\n\n\n [ 混同行列 ]\n[[ 94  11]\n [  5 175]]\n"
     ]
    }
   ],
   "source": [
    "# ロジスティック回帰\n",
    "import sys\n",
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV #グリッドサーチのためのライブラリ\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix, precision_score, recall_score, f1_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# データのロード\n",
    "cancer = datasets.load_breast_cancer()\n",
    "\n",
    "# 特徴量（30次元）\n",
    "feature_names=cancer.feature_names\n",
    "data = cancer.data\n",
    "\n",
    "# 目的変数( malignant, benign )\n",
    "name = cancer.target_names\n",
    "label = cancer.target\n",
    "\n",
    "# ホールドアウト法（学習データ，テストデータ）\n",
    "train_data, test_data, train_label, test_label = train_test_split(data, label, test_size=0.5, random_state=None)\n",
    "\n",
    "# グリッドサーチ\n",
    "parameters = {'C': [ 0.2, 1.0 ],\n",
    "              'penalty' : [ 'l1' , 'l2' , 'none' ],\n",
    "              'solver' : [ 'newton-cg', 'lbfgs' ],\n",
    "              'max_iter' : [ 100 , 200 ]\n",
    "              }\n",
    "\n",
    "# ロジスティック回帰によるグリッドサーチ           \n",
    "model = GridSearchCV(LogisticRegression(), parameters, cv=5)\n",
    "\n",
    "# 学習\n",
    "model.fit(train_data, train_label)\n",
    "\n",
    "# 最良モデル( 変数 model は最良なモデルが求まっている ）\n",
    "best_model = model.best_estimator_\n",
    "\n",
    "print( \"\\n [ 最良なパラメータ ]\" )\n",
    "print( model.best_params_ )\n",
    "\n",
    "# 予測\n",
    "predict = best_model.predict(test_data)\n",
    "\n",
    "# 係数と切片\n",
    "print( '\\n 係数ベクトル : ' , best_model.coef_ )\n",
    "print( ' 切片 : ' , best_model.intercept_)\n",
    "\n",
    "# 予測値，教師ラベル\n",
    "print( '\\n [ 予測値  :  教師ラベル ]' )\n",
    "predict_proba = best_model.predict_proba(test_data)\n",
    "for i in range(len(test_label)):\n",
    "    print( predict_proba[i] , ':' , test_label[i] )\n",
    "    \n",
    "# 予測結果の表示\n",
    "print( \"\\n [ 予測結果 ]\" )\n",
    "print( ' accuracy  : ' , accuracy_score(test_label, predict) )\n",
    "print( ' precision : ' , precision_score(test_label, predict) )\n",
    "print( ' recall    : ' , recall_score(test_label, predict) )\n",
    "print( ' f1-score  : ' , f1_score(test_label, predict) )\n",
    "\n",
    "print( \"\\n [ 予測結果 ]\" )\n",
    "print( classification_report(test_label, predict) )\n",
    "\n",
    "print( \"\\n [ 混同行列 ]\" )\n",
    "print( confusion_matrix(test_label, predict) )\n",
    "\n",
    "# 交叉検証の結果\n",
    "#print( \"\\n [ 交叉検証の全結果 ]\" )\n",
    "#for i ,  j in model.cv_results_.items():\n",
    "#    print( i , \" : \" , j )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}