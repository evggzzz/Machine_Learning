{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.0 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "fe5656c614ed49ae0d940a02e18a4e79e27ac1a6e7394b387f34db37ee0d3976"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# 9/23 機械学習入門\n",
    "## Cancer_logistic.py\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n 係数ベクトル :  [[ 0.82681946  0.35173963 -0.01914773  0.00649207 -0.02922726 -0.12739429\n  -0.1884239  -0.0903814  -0.04906286 -0.00526464  0.04573603  0.20991506\n   0.16554865 -0.11526574 -0.00561732 -0.02680734 -0.04446087 -0.01463333\n  -0.00478777 -0.00240801  0.88923911 -0.39089774  0.04090957 -0.03223482\n  -0.05775775 -0.32373208 -0.47230005 -0.15816935 -0.08923601 -0.0267871 ]]\n 切片 :  [0.15434619]\n\n [ 予測値  :  教師ラベル ]\n[0.00494191 0.99505809] : 1\n[9.99369756e-01 6.30243735e-04] : 0\n[0.02608425 0.97391575] : 1\n[0.82289334 0.17710666] : 0\n[9.99880641e-01 1.19358741e-04] : 0\n[9.99999995e-01 5.38927092e-09] : 0\n[1.00000000e+00 1.73449413e-15] : 0\n[0.01095828 0.98904172] : 1\n[0.0048003 0.9951997] : 1\n[6.81098490e-04 9.99318902e-01] : 1\n[0.04124127 0.95875873] : 1\n[9.99978340e-01 2.16601601e-05] : 0\n[9.99663496e-01 3.36503558e-04] : 0\n[0.67729601 0.32270399] : 0\n[0.17275854 0.82724146] : 1\n[0.41888106 0.58111894] : 1\n[0.00752642 0.99247358] : 1\n[0.01854892 0.98145108] : 1\n[0.04097022 0.95902978] : 1\n[0.19470644 0.80529356] : 1\n[9.99999541e-01 4.59329669e-07] : 0\n[0.00419585 0.99580415] : 1\n[0.02049102 0.97950898] : 1\n[0.23998136 0.76001864] : 1\n[0.00207957 0.99792043] : 1\n[9.99999999e-01 5.77932535e-10] : 0\n[0.01518886 0.98481114] : 1\n[0.77709596 0.22290404] : 0\n[0.20829592 0.79170408] : 0\n[0.28917766 0.71082234] : 1\n[0.89522211 0.10477789] : 0\n[9.99980943e-01 1.90565797e-05] : 0\n[9.17167050e-04 9.99082833e-01] : 1\n[0.95998863 0.04001137] : 0\n[9.99999981e-01 1.88008792e-08] : 0\n[0.99415992 0.00584008] : 0\n[0.02374643 0.97625357] : 1\n[0.00468072 0.99531928] : 1\n[0.06290978 0.93709022] : 1\n[0.01442295 0.98557705] : 1\n[0.00137677 0.99862323] : 1\n[0.02674204 0.97325796] : 1\n[9.99791322e-01 2.08677930e-04] : 0\n[0.3488951 0.6511049] : 0\n[0.09531904 0.90468096] : 1\n[0.05434011 0.94565989] : 1\n[0.20202914 0.79797086] : 1\n[0.04754964 0.95245036] : 1\n[0.93274716 0.06725284] : 0\n[9.99999998e-01 2.41526068e-09] : 0\n[9.99999222e-01 7.77801780e-07] : 0\n[0.00573721 0.99426279] : 1\n[0.18102997 0.81897003] : 0\n[0.00216723 0.99783277] : 1\n[9.99995822e-01 4.17768557e-06] : 0\n[0.7060888 0.2939112] : 1\n[1.00000000e+00 9.19397695e-11] : 0\n[0.97217584 0.02782416] : 0\n[0.00392527 0.99607473] : 1\n[8.9020045e-04 9.9910980e-01] : 1\n[0.08448167 0.91551833] : 1\n[0.88730699 0.11269301] : 1\n[0.76903751 0.23096249] : 1\n[0.83962476 0.16037524] : 0\n[0.99424321 0.00575679] : 0\n[1.00000000e+00 2.26726494e-13] : 0\n[9.99999997e-01 2.99704580e-09] : 0\n[0.0011213 0.9988787] : 1\n[0.95763887 0.04236113] : 1\n[9.99989792e-01 1.02075479e-05] : 0\n[0.00791549 0.99208451] : 1\n[0.11080339 0.88919661] : 0\n[0.0163616 0.9836384] : 1\n[0.00521235 0.99478765] : 1\n[0.98418455 0.01581545] : 0\n[0.09585212 0.90414788] : 1\n[0.14277981 0.85722019] : 1\n[0.13729809 0.86270191] : 1\n[0.02715492 0.97284508] : 1\n[0.02553458 0.97446542] : 1\n[0.01427666 0.98572334] : 1\n[0.00622047 0.99377953] : 1\n[0.00932785 0.99067215] : 1\n[0.03426865 0.96573135] : 1\n[0.01113071 0.98886929] : 1\n[0.07805221 0.92194779] : 1\n[1.00000000e+00 2.55235923e-10] : 0\n[0.27812784 0.72187216] : 0\n[0.35101028 0.64898972] : 1\n[0.01387906 0.98612094] : 1\n[0.00422413 0.99577587] : 1\n[0.00188297 0.99811703] : 1\n[9.99998518e-01 1.48182434e-06] : 0\n[0.00143259 0.99856741] : 1\n[1.00000000e+00 5.39748072e-11] : 0\n[0.00346589 0.99653411] : 1\n[0.01325462 0.98674538] : 1\n[0.0106131 0.9893869] : 1\n[0.03200894 0.96799106] : 1\n[5.30854030e-04 9.99469146e-01] : 1\n[9.99999998e-01 1.68593659e-09] : 0\n[0.96374587 0.03625413] : 0\n[1.000000e+00 4.071696e-16] : 0\n[0.15281596 0.84718404] : 1\n[0.05278156 0.94721844] : 1\n[0.00242674 0.99757326] : 1\n[0.01904089 0.98095911] : 1\n[1.00000000e+00 1.00924107e-34] : 0\n[1.00000000e+00 1.25325868e-23] : 0\n[0.00223894 0.99776106] : 1\n[0.01015414 0.98984586] : 1\n[8.73382258e-04 9.99126618e-01] : 1\n[0.7872005 0.2127995] : 1\n[0.39605703 0.60394297] : 0\n[0.01986615 0.98013385] : 1\n[0.01446426 0.98553574] : 1\n[0.01659255 0.98340745] : 1\n[0.00407947 0.99592053] : 1\n[0.00262482 0.99737518] : 1\n[0.00148019 0.99851981] : 1\n[0.13427181 0.86572819] : 0\n[0.73342962 0.26657038] : 0\n[0.95543125 0.04456875] : 0\n[0.99434251 0.00565749] : 0\n[0.00317263 0.99682737] : 1\n[5.64987117e-04 9.99435013e-01] : 1\n[0.01049195 0.98950805] : 1\n[0.00165334 0.99834666] : 1\n[0.59134145 0.40865855] : 1\n[0.00795913 0.99204087] : 1\n[0.05338709 0.94661291] : 1\n[0.00280573 0.99719427] : 1\n[0.00402682 0.99597318] : 1\n[0.11066013 0.88933987] : 1\n[0.07103843 0.92896157] : 1\n[0.76631132 0.23368868] : 0\n[0.26906582 0.73093418] : 1\n[0.05330048 0.94669952] : 1\n[0.00149561 0.99850439] : 1\n[0.99814635 0.00185365] : 0\n[0.00336695 0.99663305] : 1\n[0.01582308 0.98417692] : 1\n[0.09425227 0.90574773] : 1\n[0.05360505 0.94639495] : 1\n[0.01797462 0.98202538] : 1\n[0.0358254 0.9641746] : 0\n[0.0238295 0.9761705] : 1\n[0.25918297 0.74081703] : 1\n[0.00560303 0.99439697] : 1\n[0.59001285 0.40998715] : 0\n[0.07109805 0.92890195] : 1\n[0.02636692 0.97363308] : 1\n[0.28924684 0.71075316] : 1\n[0.00115228 0.99884772] : 1\n[0.00729338 0.99270662] : 1\n[0.01468734 0.98531266] : 1\n[0.03866372 0.96133628] : 1\n[9.42146713e-04 9.99057853e-01] : 1\n[0.03116942 0.96883058] : 1\n[0.94711722 0.05288278] : 0\n[0.98626036 0.01373964] : 0\n[0.0047969 0.9952031] : 1\n[0.00205819 0.99794181] : 1\n[0.00634148 0.99365852] : 1\n[0.00264761 0.99735239] : 1\n[0.22750269 0.77249731] : 0\n[0.86536157 0.13463843] : 1\n[0.07860323 0.92139677] : 1\n[0.25247458 0.74752542] : 0\n[0.00424015 0.99575985] : 1\n[0.01115245 0.98884755] : 1\n[0.02316026 0.97683974] : 1\n[0.00649159 0.99350841] : 1\n[0.99876896 0.00123104] : 0\n[0.03137004 0.96862996] : 0\n[0.9531868 0.0468132] : 0\n[0.00595611 0.99404389] : 1\n[0.00558569 0.99441431] : 1\n[0.18349232 0.81650768] : 1\n[1.00000000e+00 8.65126416e-16] : 0\n[1.00000000e+00 1.08114984e-10] : 0\n[9.99998465e-01 1.53546250e-06] : 0\n[9.99997148e-01 2.85214011e-06] : 0\n[0.99122774 0.00877226] : 0\n[0.00164015 0.99835985] : 1\n[0.95468853 0.04531147] : 0\n[0.0011478 0.9988522] : 1\n[0.00604327 0.99395673] : 1\n[0.04374161 0.95625839] : 1\n[0.99625542 0.00374458] : 0\n[0.65210719 0.34789281] : 0\n[0.04070013 0.95929987] : 1\n[9.99659122e-01 3.40877920e-04] : 0\n[0.01737442 0.98262558] : 1\n[0.03937623 0.96062377] : 1\n[0.02134034 0.97865966] : 1\n[9.99495290e-01 5.04709675e-04] : 0\n[0.55686 0.44314] : 0\n[0.31118284 0.68881716] : 1\n[1.76106279e-04 9.99823894e-01] : 1\n[0.3401399 0.6598601] : 1\n[0.01258178 0.98741822] : 1\n[0.81215501 0.18784499] : 0\n[0.98731028 0.01268972] : 0\n[9.99999991e-01 8.60414013e-09] : 0\n[0.51013731 0.48986269] : 1\n[0.01060173 0.98939827] : 1\n[0.02955184 0.97044816] : 1\n[0.00260318 0.99739682] : 1\n[0.01576218 0.98423782] : 1\n[0.01049431 0.98950569] : 1\n[0.33471681 0.66528319] : 1\n[0.00420967 0.99579033] : 1\n[0.00192335 0.99807665] : 1\n[0.12263527 0.87736473] : 1\n[0.0032686 0.9967314] : 1\n[9.99840344e-01 1.59655695e-04] : 0\n[9.99999954e-01 4.64181263e-08] : 0\n[1.00000000e+00 2.66985163e-24] : 0\n[9.99965528e-01 3.44716889e-05] : 0\n[0.00845024 0.99154976] : 1\n[9.99999916e-01 8.43444830e-08] : 0\n[9.99651499e-01 3.48500809e-04] : 0\n[0.70184978 0.29815022] : 0\n[9.99564637e-01 4.35362712e-04] : 0\n[0.00520455 0.99479545] : 1\n[0.01481534 0.98518466] : 1\n[0.23211197 0.76788803] : 1\n[0.05968725 0.94031275] : 1\n[0.01067601 0.98932399] : 1\n[5.03007116e-04 9.99496993e-01] : 1\n[9.99998582e-01 1.41769821e-06] : 0\n[9.99300746e-01 6.99254360e-04] : 0\n[0.02224356 0.97775644] : 1\n[9.99999585e-01 4.14976959e-07] : 0\n[0.0050752 0.9949248] : 1\n[0.01401099 0.98598901] : 1\n[0.90908028 0.09091972] : 0\n[0.12635723 0.87364277] : 1\n[0.00239361 0.99760639] : 1\n[0.08225769 0.91774231] : 1\n[0.29029764 0.70970236] : 0\n[0.00352424 0.99647576] : 1\n[0.03790122 0.96209878] : 1\n[1.0000000e+00 1.2396792e-11] : 0\n[0.00394685 0.99605315] : 1\n[0.96802439 0.03197561] : 0\n[9.99578263e-01 4.21737336e-04] : 0\n[0.00744254 0.99255746] : 1\n[0.01258571 0.98741429] : 1\n[0.98454038 0.01545962] : 0\n[0.00367265 0.99632735] : 1\n[0.07761529 0.92238471] : 0\n[0.00627936 0.99372064] : 1\n[9.99999995e-01 4.79671210e-09] : 0\n[9.99990335e-01 9.66515736e-06] : 0\n[0.22125248 0.77874752] : 1\n[0.05376259 0.94623741] : 1\n[0.00667407 0.99332593] : 1\n[0.65970265 0.34029735] : 0\n[1.00000000e+00 1.77001216e-12] : 0\n[0.00111291 0.99888709] : 1\n[0.00327404 0.99672596] : 1\n[0.00885689 0.99114311] : 1\n[0.03247919 0.96752081] : 1\n[0.01094709 0.98905291] : 1\n[1.00000000e+00 8.28970362e-15] : 0\n[9.99999947e-01 5.28488401e-08] : 0\n[0.01677912 0.98322088] : 1\n[9.99996124e-01 3.87556509e-06] : 0\n[9.99999976e-01 2.44035962e-08] : 0\n[0.25447582 0.74552418] : 1\n[0.00414608 0.99585392] : 1\n[0.03539177 0.96460823] : 1\n[0.07082326 0.92917674] : 1\n[1.00000000e+00 1.12323732e-17] : 0\n[4.31965713e-04 9.99568034e-01] : 1\n[0.00117729 0.99882271] : 1\n[0.13431246 0.86568754] : 1\n[9.62262665e-04 9.99037737e-01] : 1\n[9.99999423e-01 5.76563064e-07] : 0\n[0.76009172 0.23990828] : 1\n[9.99275292e-01 7.24708371e-04] : 0\n[0.01601641 0.98398359] : 1\n[1.00000000e+00 7.22773247e-12] : 0\n\n [ 予測結果 ]\n accuracy  :  0.9228070175438596\n precision :  0.93048128342246\n recall    :  0.9508196721311475\n f1-score  :  0.9405405405405407\n\n [ 予測結果 ]\n              precision    recall  f1-score   support\n\n           0       0.91      0.87      0.89       102\n           1       0.93      0.95      0.94       183\n\n    accuracy                           0.92       285\n   macro avg       0.92      0.91      0.92       285\nweighted avg       0.92      0.92      0.92       285\n\n\n [ 混同行列 ]\n[[ 89  13]\n [  9 174]]\n"
     ]
    }
   ],
   "source": [
    "# ロジスティック回帰\n",
    "import sys\n",
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix, precision_score, recall_score, f1_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# データのロード\n",
    "cancer = datasets.load_breast_cancer()\n",
    "\n",
    "# 特徴量（30次元）\n",
    "feature_names=cancer.feature_names\n",
    "data = cancer.data\n",
    "\n",
    "# 目的変数( malignant, benign )\n",
    "name = cancer.target_names\n",
    "label = cancer.target #分類問題では正解値として正解ラベルを学習時に与える,二値分類問題では，正例(1)もしくは負例(0)\n",
    "\n",
    "# ホールドアウト法（学習データ，テストデータ）\n",
    "train_data, test_data, train_label, test_label = train_test_split(data, label, test_size=0.5, random_state=None)\n",
    "\n",
    "# ロジスティック回帰 \n",
    "# (ソルバー：記憶制限付き準ニュートン法 L-BFGS)\n",
    "# (ペナルティ項：2ノルム)\n",
    "model = LogisticRegression(C=1.0,penalty='l2',solver='lbfgs',max_iter=100)\n",
    "\n",
    "# 学習\n",
    "model.fit(train_data, train_label)\n",
    "\n",
    "# 予測\n",
    "predict = model.predict(test_data)\n",
    "\n",
    "# 係数と切片\n",
    "print( '\\n 係数ベクトル : ' , model.coef_ )\n",
    "print( ' 切片 : ' , model.intercept_)\n",
    "\n",
    "# 予測値，教師ラベル\n",
    "print( '\\n [ 予測値  :  教師ラベル ]' )\n",
    "predict_proba = model.predict_proba(test_data)\n",
    "for i in range(len(test_label)):\n",
    "    print( predict_proba[i] , ':' , test_label[i] ) #predict_proba[i] = [p(0),p(1)][i]\n",
    "    \n",
    "\n",
    "# 予測結果の表示\n",
    "print( \"\\n [ 予測結果 ]\" )\n",
    "print( ' accuracy  : ' , accuracy_score(test_label, predict) )\n",
    "print( ' precision : ' , precision_score(test_label, predict) )\n",
    "print( ' recall    : ' , recall_score(test_label, predict) )\n",
    "print( ' f1-score  : ' , f1_score(test_label, predict) )\n",
    "\n",
    "print( \"\\n [ 予測結果 ]\" )\n",
    "print( classification_report(test_label, predict) )\n",
    "\n",
    "print( \"\\n [ 混同行列 ]\" )\n",
    "print( confusion_matrix(test_label, predict) )\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[1.799e+01 1.038e+01 1.228e+02 ... 2.654e-01 4.601e-01 1.189e-01]\n [2.057e+01 1.777e+01 1.329e+02 ... 1.860e-01 2.750e-01 8.902e-02]\n [1.969e+01 2.125e+01 1.300e+02 ... 2.430e-01 3.613e-01 8.758e-02]\n ...\n [1.660e+01 2.808e+01 1.083e+02 ... 1.418e-01 2.218e-01 7.820e-02]\n [2.060e+01 2.933e+01 1.401e+02 ... 2.650e-01 4.087e-01 1.240e-01]\n [7.760e+00 2.454e+01 4.792e+01 ... 0.000e+00 2.871e-01 7.039e-02]]\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "569"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "# データのロード\n",
    "cancer = datasets.load_breast_cancer()\n",
    "\n",
    "# 特徴量（30次元）\n",
    "feature_names=cancer.feature_names\n",
    "data = cancer.data\n",
    "\n",
    "# 目的変数( malignant, benign )\n",
    "name = cancer.target_names\n",
    "label = cancer.target\n",
    "#print(cancer.feature_names)\n",
    "print(cancer.data)\n",
    "len(cancer.data)\n",
    "#print(name)"
   ]
  },
  {
   "source": [
    "## logistic_CV.py"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      " fit_time        : [0.07477999 0.0356791  0.03619599 0.03664112 0.04191089]\n score_time      : [0.00328898 0.00317788 0.00240493 0.00232387 0.00252509]\n test_accuracy   : [0.92982456 0.92982456 0.96491228 0.93859649 0.95575221]\n test_precision  : [0.94103194 0.92916806 0.96722973 0.93601737 0.95083056]\n test_recall     : [0.9115624  0.9207337  0.95734127 0.93154762 0.95506372]\n test_f          : [0.92297297 0.92460317 0.96191113 0.93369339 0.95285774]\n"
     ]
    }
   ],
   "source": [
    "# ロジスティック回帰（交叉検証）\n",
    "import sys\n",
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "# データのロード\n",
    "cancer = datasets.load_breast_cancer()\n",
    "\n",
    "# 特徴量（30次元）\n",
    "feature_names=cancer.feature_names\n",
    "data = cancer.data\n",
    "\n",
    "# 目的変数( malignant, benign )\n",
    "name = cancer.target_names\n",
    "label = cancer.target\n",
    "\n",
    "# ロジスティック回帰\n",
    "model = LogisticRegression(C=1.0,penalty='l2',solver='lbfgs',max_iter=100)\n",
    "\n",
    "# 交叉検証\n",
    "score = { \"accuracy\": \"accuracy\",\n",
    "            \"precision\": \"precision_macro\",\n",
    "            \"recall\": \"recall_macro\",\n",
    "            \"f\":\"f1_macro\"\n",
    "            }\n",
    "\n",
    "result = cross_validate(model, data, label, cv=5, scoring=score,)\n",
    "\n",
    "# 結果の表示\n",
    "for i , j in result.items():\n",
    "    print( \" {0:15s} : {1}\".format( i , j ) )"
   ]
  },
  {
   "source": [
    "## logistic_GS.py"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n [ 最良なパラメータ ]\n{'C': 0.2, 'max_iter': 100, 'penalty': 'none', 'solver': 'newton-cg'}\n\n 係数ベクトル :  [[ 5.52904987e+00 -1.59149498e+00  8.03708547e-01 -7.67465823e-02\n  -1.64261464e+01  3.66204844e+01 -2.22085957e+01 -3.43412539e+01\n   8.60696490e+00  7.69871710e+00 -1.58642740e+01 -1.33425114e+00\n  -9.54645170e-01 -9.34909375e-02 -1.42542310e+00  5.92780944e+01\n   4.06252598e+01 -1.03357356e+01  1.70885973e+01  9.55782994e+00\n  -4.11254997e+00  6.67883448e-01 -1.10208873e-01  5.96284645e-04\n  -3.81623953e+01  1.56962300e+01 -1.94389982e+01 -9.17632353e+01\n  -3.17481233e+01  7.29211198e+00]]\n 切片 :  [23.10940642]\n\n [ 予測値  :  教師ラベル ]\n[3.37175429e-04 9.99662825e-01] : 1\n[1.00000000e+00 1.00582191e-70] : 0\n[1.97221580e-04 9.99802778e-01] : 1\n[3.29373981e-08 9.99999967e-01] : 1\n[9.99999827e-01 1.72853863e-07] : 0\n[1.73804829e-05 9.99982620e-01] : 1\n[6.22962992e-09 9.99999994e-01] : 1\n[1.00000000e+00 4.45889628e-15] : 0\n[1.89004520e-04 9.99810995e-01] : 1\n[1.42514297e-06 9.99998575e-01] : 1\n[2.76646964e-08 9.99999972e-01] : 1\n[9.99999998e-01 2.02531968e-09] : 0\n[0.00105142 0.99894858] : 1\n[9.99999960e-01 3.98284554e-08] : 0\n[0.15837644 0.84162356] : 1\n[1.00000000e+00 2.55795695e-24] : 0\n[1.07889823e-08 9.99999989e-01] : 1\n[1.25679388e-08 9.99999987e-01] : 1\n[0.18607862 0.81392138] : 1\n[2.08435467e-04 9.99791565e-01] : 1\n[0.00224109 0.99775891] : 1\n[0.96711682 0.03288318] : 0\n[4.95496977e-11 1.00000000e+00] : 1\n[1.29393008e-05 9.99987061e-01] : 1\n[8.03997032e-06 9.99991960e-01] : 1\n[0.00371343 0.99628657] : 1\n[1.26424865e-07 9.99999874e-01] : 1\n[7.67746530e-07 9.99999232e-01] : 1\n[2.60838304e-07 9.99999739e-01] : 1\n[9.99807160e-01 1.92839573e-04] : 0\n[9.99999999e-01 1.30184574e-09] : 0\n[1.00000000e+00 1.55458493e-12] : 0\n[2.31164839e-07 9.99999769e-01] : 1\n[0.0046368 0.9953632] : 1\n[1.00000000e+00 1.26875259e-15] : 0\n[1.49494529e-04 9.99850505e-01] : 1\n[1.54254609e-10 1.00000000e+00] : 1\n[9.99698233e-01 3.01766718e-04] : 0\n[0.99820236 0.00179764] : 0\n[8.62114824e-11 1.00000000e+00] : 1\n[1.00000000e+00 1.80345461e-23] : 0\n[0.00585509 0.99414491] : 0\n[7.28548333e-11 1.00000000e+00] : 1\n[6.33069157e-05 9.99936693e-01] : 1\n[1.00000000e+00 1.00246484e-13] : 0\n[9.99992963e-01 7.03703481e-06] : 0\n[1.00000000e+00 5.06113307e-27] : 0\n[9.99999689e-01 3.11292922e-07] : 0\n[0.99013168 0.00986832] : 1\n[4.29139991e-04 9.99570860e-01] : 0\n[1.00000000e+00 2.55676051e-11] : 0\n[2.44321740e-06 9.99997557e-01] : 1\n[0.03667163 0.96332837] : 1\n[1.0000000e+00 1.1979642e-22] : 0\n[0.83497724 0.16502276] : 0\n[9.99999997e-01 2.65622746e-09] : 0\n[0.54435679 0.45564321] : 1\n[9.99999715e-01 2.84599511e-07] : 0\n[5.33372026e-05 9.99946663e-01] : 1\n[1.00000000e+00 9.13507839e-15] : 0\n[1.00000000e+00 2.58605071e-30] : 0\n[1.99036756e-08 9.99999980e-01] : 1\n[2.48796539e-10 1.00000000e+00] : 1\n[1.82168058e-10 1.00000000e+00] : 1\n[1.15619767e-06 9.99998844e-01] : 1\n[8.91047047e-09 9.99999991e-01] : 1\n[1.19080857e-07 9.99999881e-01] : 1\n[9.99461648e-01 5.38352020e-04] : 1\n[0.00814146 0.99185854] : 1\n[1.32052432e-06 9.99998679e-01] : 1\n[2.10527711e-07 9.99999789e-01] : 1\n[1.00000000e+00 4.76584528e-15] : 0\n[1.05624398e-11 1.00000000e+00] : 1\n[7.09629112e-06 9.99992904e-01] : 1\n[9.99999972e-01 2.82571373e-08] : 0\n[1.03839569e-06 9.99998962e-01] : 1\n[9.99999972e-01 2.77350187e-08] : 0\n[0.00786081 0.99213919] : 1\n[2.28049579e-10 1.00000000e+00] : 1\n[9.99999856e-01 1.43835887e-07] : 0\n[2.12837505e-06 9.99997872e-01] : 1\n[1.00000000e+00 6.92958659e-14] : 0\n[1.72510682e-05 9.99982749e-01] : 1\n[6.19199270e-09 9.99999994e-01] : 1\n[1.00000000e+00 3.23263985e-17] : 0\n[1.00000000e+00 3.88232804e-44] : 0\n[1.00000000e+00 1.93478209e-11] : 0\n[6.67013555e-10 9.99999999e-01] : 1\n[9.99091402e-01 9.08598353e-04] : 1\n[0.32772318 0.67227682] : 0\n[3.14318493e-04 9.99685682e-01] : 1\n[1.73010681e-05 9.99982699e-01] : 1\n[1.00000000e+00 1.01499983e-35] : 0\n[8.43432682e-05 9.99915657e-01] : 1\n[7.25932980e-09 9.99999993e-01] : 1\n[2.68583524e-06 9.99997314e-01] : 1\n[4.15445234e-09 9.99999996e-01] : 1\n[0.0023521 0.9976479] : 0\n[1.00000000e+00 8.86559398e-18] : 0\n[7.67887631e-09 9.99999992e-01] : 1\n[0.95683372 0.04316628] : 1\n[0.09106687 0.90893313] : 0\n[3.28668675e-07 9.99999671e-01] : 1\n[4.62927804e-08 9.99999954e-01] : 1\n[9.76414061e-10 9.99999999e-01] : 1\n[0.00190797 0.99809203] : 1\n[2.58464583e-09 9.99999997e-01] : 1\n[9.72103065e-10 9.99999999e-01] : 1\n[2.91994738e-06 9.99997080e-01] : 1\n[1.00000000e+00 8.06192636e-20] : 0\n[9.99999995e-01 5.25270588e-09] : 0\n[1.00000000e+00 5.35294052e-15] : 0\n[4.19768846e-06 9.99995802e-01] : 1\n[3.28513239e-09 9.99999997e-01] : 1\n[1.61164002e-05 9.99983884e-01] : 1\n[9.99995903e-01 4.09676560e-06] : 0\n[7.95636446e-10 9.99999999e-01] : 1\n[1.00000000e+00 5.19718759e-13] : 0\n[2.17066738e-07 9.99999783e-01] : 1\n[2.19162665e-06 9.99997808e-01] : 1\n[9.99886040e-01 1.13959719e-04] : 0\n[1.49070184e-06 9.99998509e-01] : 1\n[5.69170933e-10 9.99999999e-01] : 1\n[5.80965387e-08 9.99999942e-01] : 1\n[9.99999601e-01 3.99158535e-07] : 0\n[1.00000000e+00 7.66566735e-14] : 0\n[9.20264653e-09 9.99999991e-01] : 1\n[9.99998876e-01 1.12382520e-06] : 0\n[9.99996728e-01 3.27168952e-06] : 0\n[0.99725147 0.00274853] : 0\n[0.57688107 0.42311893] : 0\n[7.12437291e-08 9.99999929e-01] : 1\n[1.0000000e+00 2.2245719e-19] : 0\n[1.98384578e-04 9.99801615e-01] : 1\n[1.00000000e+00 2.66014061e-10] : 0\n[7.02242092e-07 9.99999298e-01] : 1\n[2.29656294e-11 1.00000000e+00] : 1\n[1.00000000e+00 1.86429446e-18] : 0\n[0.00103691 0.99896309] : 1\n[4.50346551e-08 9.99999955e-01] : 1\n[9.99999998e-01 1.61938356e-09] : 0\n[1.00000000e+00 5.99568663e-20] : 0\n[1.00000000e+00 1.47698096e-24] : 0\n[1.00000000e+00 6.12062979e-31] : 0\n[2.48955853e-05 9.99975104e-01] : 1\n[2.22786792e-05 9.99977721e-01] : 1\n[1.18943845e-07 9.99999881e-01] : 1\n[2.65702438e-09 9.99999997e-01] : 1\n[4.21854806e-05 9.99957815e-01] : 1\n[9.24291045e-07 9.99999076e-01] : 1\n[1.00000000e+00 6.98422578e-25] : 0\n[3.38218342e-12 1.00000000e+00] : 1\n[0.00697937 0.99302063] : 1\n[0.4064254 0.5935746] : 1\n[1.00000000e+00 2.14651564e-17] : 0\n[2.92607690e-07 9.99999707e-01] : 1\n[0.99730664 0.00269336] : 0\n[6.89625220e-08 9.99999931e-01] : 1\n[4.50204723e-05 9.99954980e-01] : 1\n[2.59758868e-05 9.99974024e-01] : 1\n[9.99996686e-01 3.31437048e-06] : 0\n[7.62384100e-09 9.99999992e-01] : 1\n[2.70399481e-09 9.99999997e-01] : 1\n[6.44260378e-09 9.99999994e-01] : 1\n[7.81547937e-10 9.99999999e-01] : 1\n[4.58424465e-07 9.99999542e-01] : 1\n[5.53845192e-10 9.99999999e-01] : 1\n[3.96973847e-05 9.99960303e-01] : 1\n[1.00000000e+00 2.63726214e-18] : 0\n[0.00696893 0.99303107] : 1\n[0.98552569 0.01447431] : 0\n[7.56972485e-10 9.99999999e-01] : 1\n[0.00989953 0.99010047] : 1\n[6.55597534e-06 9.99993444e-01] : 1\n[0.99764646 0.00235354] : 0\n[9.99999996e-01 4.04448568e-09] : 0\n[9.37903311e-10 9.99999999e-01] : 1\n[9.99922900e-01 7.71003677e-05] : 0\n[6.41836806e-10 9.99999999e-01] : 1\n[1.00000000e+00 6.37591798e-22] : 0\n[0.00285039 0.99714961] : 1\n[1.38041178e-08 9.99999986e-01] : 1\n[8.63300764e-10 9.99999999e-01] : 1\n[4.59757999e-07 9.99999540e-01] : 1\n[9.99993875e-01 6.12493447e-06] : 0\n[8.88393169e-08 9.99999911e-01] : 1\n[3.81663109e-04 9.99618337e-01] : 1\n[8.57087734e-11 1.00000000e+00] : 1\n[8.20488122e-11 1.00000000e+00] : 1\n[1.00000000e+00 3.01900457e-18] : 0\n[1.00000000e+00 5.18960943e-22] : 0\n[1.38368872e-09 9.99999999e-01] : 1\n[9.99989596e-01 1.04041259e-05] : 0\n[3.76246767e-09 9.99999996e-01] : 1\n[4.30995799e-04 9.99569004e-01] : 0\n[2.04720485e-09 9.99999998e-01] : 1\n[2.80353651e-09 9.99999997e-01] : 1\n[0.0050396 0.9949604] : 1\n[1.53538249e-09 9.99999998e-01] : 1\n[1.3957388e-07 9.9999986e-01] : 1\n[3.33804475e-08 9.99999967e-01] : 1\n[5.88524374e-07 9.99999411e-01] : 1\n[1.95137357e-06 9.99998049e-01] : 1\n[2.18770949e-05 9.99978123e-01] : 1\n[3.63669095e-11 1.00000000e+00] : 1\n[1.40821030e-07 9.99999859e-01] : 1\n[1.53712809e-06 9.99998463e-01] : 1\n[1.00164151e-08 9.99999990e-01] : 1\n[1.10661791e-07 9.99999889e-01] : 1\n[0.27166992 0.72833008] : 1\n[4.70256238e-05 9.99952974e-01] : 1\n[8.62141289e-07 9.99999138e-01] : 1\n[0.00185852 0.99814148] : 0\n[2.03903561e-12 1.00000000e+00] : 1\n[1.0000000e+00 1.3717514e-30] : 0\n[6.12467853e-05 9.99938753e-01] : 1\n[3.32955885e-12 1.00000000e+00] : 1\n[1.00000000e+00 2.63109513e-44] : 0\n[2.41174093e-07 9.99999759e-01] : 1\n[1.00000000e+00 1.69689767e-13] : 0\n[2.34729569e-10 1.00000000e+00] : 1\n[9.39544422e-06 9.99990605e-01] : 1\n[1.00000000e+00 6.42426166e-45] : 0\n[1.00000000e+00 2.57663591e-19] : 0\n[1.00000000e+00 1.14963564e-31] : 0\n[9.78314529e-04 9.99021685e-01] : 1\n[5.16316992e-06 9.99994837e-01] : 1\n[2.59756629e-06 9.99997402e-01] : 1\n[3.69173778e-06 9.99996308e-01] : 1\n[0.06897528 0.93102472] : 0\n[1.22251431e-09 9.99999999e-01] : 1\n[8.57123705e-10 9.99999999e-01] : 1\n[0.99770997 0.00229003] : 0\n[1.13005338e-04 9.99886995e-01] : 1\n[0.0012934 0.9987066] : 1\n[3.43156147e-08 9.99999966e-01] : 1\n[9.99894542e-01 1.05457856e-04] : 0\n[6.30878960e-07 9.99999369e-01] : 1\n[0.63719768 0.36280232] : 0\n[0.86228275 0.13771725] : 0\n[1.14384738e-08 9.99999989e-01] : 1\n[1.00000000e+00 2.50304762e-15] : 0\n[0.0065969 0.9934031] : 1\n[2.57349697e-13 1.00000000e+00] : 1\n[1.06971099e-10 1.00000000e+00] : 1\n[1.97259986e-10 1.00000000e+00] : 1\n[2.46953505e-06 9.99997530e-01] : 1\n[1.00000000e+00 6.53860246e-18] : 0\n[9.99995970e-01 4.03010339e-06] : 0\n[3.13284954e-11 1.00000000e+00] : 1\n[1.00000000e+00 3.40667948e-10] : 0\n[1.00000000e+00 4.55392367e-16] : 0\n[1.00000000e+00 6.62199283e-11] : 0\n[5.18384069e-08 9.99999948e-01] : 1\n[9.99999385e-01 6.14809369e-07] : 0\n[3.10483959e-07 9.99999690e-01] : 1\n[1.0000000e+00 2.3853507e-34] : 0\n[6.37257928e-07 9.99999363e-01] : 1\n[5.50805016e-08 9.99999945e-01] : 1\n[4.86496043e-07 9.99999514e-01] : 1\n[1.00000000e+00 3.81867132e-11] : 0\n[6.21011464e-10 9.99999999e-01] : 1\n[8.80623183e-08 9.99999912e-01] : 1\n[1.00000000e+00 4.10705833e-31] : 0\n[9.99844107e-01 1.55893030e-04] : 0\n[1.00000000e+00 5.39676798e-22] : 0\n[0.19443049 0.80556951] : 0\n[0.25693094 0.74306906] : 1\n[1.00000000e+00 3.50637961e-14] : 0\n[1.08844045e-11 1.00000000e+00] : 1\n[9.99999895e-01 1.04936033e-07] : 0\n[4.96491737e-13 1.00000000e+00] : 1\n[0.03509024 0.96490976] : 0\n[3.69758289e-07 9.99999630e-01] : 1\n[9.07171678e-04 9.99092828e-01] : 0\n[4.6032067e-12 1.0000000e+00] : 1\n[6.10013196e-09 9.99999994e-01] : 1\n[1.84583968e-05 9.99981542e-01] : 1\n[3.66798969e-09 9.99999996e-01] : 1\n[3.57213051e-04 9.99642787e-01] : 1\n[2.30258732e-05 9.99976974e-01] : 1\n[1.00000000e+00 8.03641493e-23] : 0\n[9.99999995e-01 4.81499761e-09] : 0\n[5.10418374e-11 1.00000000e+00] : 1\n[5.14184251e-11 1.00000000e+00] : 1\n\n [ 予測結果 ]\n accuracy  :  0.9438596491228071\n precision :  0.9408602150537635\n recall    :  0.9722222222222222\n f1-score  :  0.9562841530054644\n\n [ 予測結果 ]\n              precision    recall  f1-score   support\n\n           0       0.95      0.90      0.92       105\n           1       0.94      0.97      0.96       180\n\n    accuracy                           0.94       285\n   macro avg       0.95      0.93      0.94       285\nweighted avg       0.94      0.94      0.94       285\n\n\n [ 混同行列 ]\n[[ 94  11]\n [  5 175]]\n"
     ]
    }
   ],
   "source": [
    "# ロジスティック回帰\n",
    "import sys\n",
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV #グリッドサーチのためのライブラリ\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix, precision_score, recall_score, f1_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# データのロード\n",
    "cancer = datasets.load_breast_cancer()\n",
    "\n",
    "# 特徴量（30次元）\n",
    "feature_names=cancer.feature_names\n",
    "data = cancer.data\n",
    "\n",
    "# 目的変数( malignant, benign )\n",
    "name = cancer.target_names\n",
    "label = cancer.target\n",
    "\n",
    "# ホールドアウト法（学習データ，テストデータ）\n",
    "train_data, test_data, train_label, test_label = train_test_split(data, label, test_size=0.5, random_state=None)\n",
    "\n",
    "# グリッドサーチ\n",
    "parameters = {'C': [ 0.2, 1.0 ],\n",
    "              'penalty' : [ 'l1' , 'l2' , 'none' ],\n",
    "              'solver' : [ 'newton-cg', 'lbfgs' ],\n",
    "              'max_iter' : [ 100 , 200 ]\n",
    "              }\n",
    "\n",
    "# ロジスティック回帰によるグリッドサーチ           \n",
    "model = GridSearchCV(LogisticRegression(), parameters, cv=5)\n",
    "\n",
    "# 学習\n",
    "model.fit(train_data, train_label)\n",
    "\n",
    "# 最良モデル( 変数 model は最良なモデルが求まっている ）\n",
    "best_model = model.best_estimator_\n",
    "\n",
    "print( \"\\n [ 最良なパラメータ ]\" )\n",
    "print( model.best_params_ )\n",
    "\n",
    "# 予測\n",
    "predict = best_model.predict(test_data)\n",
    "\n",
    "# 係数と切片\n",
    "print( '\\n 係数ベクトル : ' , best_model.coef_ )\n",
    "print( ' 切片 : ' , best_model.intercept_)\n",
    "\n",
    "# 予測値，教師ラベル\n",
    "print( '\\n [ 予測値  :  教師ラベル ]' )\n",
    "predict_proba = best_model.predict_proba(test_data)\n",
    "for i in range(len(test_label)):\n",
    "    print( predict_proba[i] , ':' , test_label[i] )\n",
    "    \n",
    "# 予測結果の表示\n",
    "print( \"\\n [ 予測結果 ]\" )\n",
    "print( ' accuracy  : ' , accuracy_score(test_label, predict) )\n",
    "print( ' precision : ' , precision_score(test_label, predict) )\n",
    "print( ' recall    : ' , recall_score(test_label, predict) )\n",
    "print( ' f1-score  : ' , f1_score(test_label, predict) )\n",
    "\n",
    "print( \"\\n [ 予測結果 ]\" )\n",
    "print( classification_report(test_label, predict) )\n",
    "\n",
    "print( \"\\n [ 混同行列 ]\" )\n",
    "print( confusion_matrix(test_label, predict) )\n",
    "\n",
    "# 交叉検証の結果\n",
    "#print( \"\\n [ 交叉検証の全結果 ]\" )\n",
    "#for i ,  j in model.cv_results_.items():\n",
    "#    print( i , \" : \" , j )"
   ]
  },
  {
   "source": [
    "# 10/7 練習問題①  \n",
    "学習データ(prac_1_train-1.csv)を用いてロジスィック回帰モデルを学習しなさい.  \n",
    "学習後のモデルを用いて，テストデータ(prac_1_test-1.csv)を予測しなさい.  \n",
    "評価指標(混同行列，accuracy，precision，recall，f値)も求めて下さい.  "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      " 係数ベクトル :  [[ 0.03084895 -0.02171109  0.09571813  0.02903143]\n",
      " [ 0.00782213  0.10035777 -0.09281304 -0.09434485]\n",
      " [-0.03867109 -0.07864668 -0.00290509  0.06531342]]\n",
      " 切片 :  [-1.86438231  0.97975037  0.88463193]\n",
      "\n",
      " [ 予測値  :  教師ラベル ]\n",
      "[0.66777912 0.05165947 0.28056141] : [0.]\n",
      "[0.84255282 0.06272307 0.09472411] : [0.]\n",
      "[0.58105936 0.05658006 0.36236058] : [0.]\n",
      "[0.59841729 0.00491221 0.39667049] : [0.]\n",
      "[0.3774422  0.00968279 0.61287501] : [0.]\n",
      "[0.51688909 0.04057868 0.44253223] : [0.]\n",
      "[0.40813022 0.18953636 0.40233342] : [0.]\n",
      "[0.31750839 0.02720998 0.65528163] : [0.]\n",
      "[0.22925054 0.01894197 0.7518075 ] : [0.]\n",
      "[0.15923999 0.80804622 0.03271379] : [0.]\n",
      "[0.72172993 0.05898756 0.2192825 ] : [0.]\n",
      "[0.88686601 0.03005754 0.08307645] : [0.]\n",
      "[0.79289679 0.10820471 0.09889849] : [0.]\n",
      "[9.82148562e-01 3.65333614e-04 1.74861044e-02] : [0.]\n",
      "[9.68758703e-01 5.70244682e-04 3.06710520e-02] : [0.]\n",
      "[8.81119820e-01 7.88147864e-04 1.18092032e-01] : [0.]\n",
      "[0.8406058  0.03890281 0.12049139] : [0.]\n",
      "[0.8725974  0.01494045 0.11246216] : [0.]\n",
      "[0.32735045 0.58011376 0.0925358 ] : [0.]\n",
      "[0.22457983 0.02629436 0.74912581] : [0.]\n",
      "[0.89491798 0.00464741 0.10043461] : [0.]\n",
      "[0.26072309 0.73063414 0.00864278] : [0.]\n",
      "[0.64390733 0.18631026 0.16978241] : [0.]\n",
      "[0.49448182 0.28300075 0.22251744] : [0.]\n",
      "[0.80852588 0.02999854 0.16147558] : [0.]\n",
      "[0.80257776 0.00767566 0.18974658] : [0.]\n",
      "[0.492494   0.35597003 0.15153598] : [0.]\n",
      "[0.67324165 0.04585351 0.28090484] : [0.]\n",
      "[5.90559830e-01 1.32556136e-04 4.09307614e-01] : [0.]\n",
      "[0.02901841 0.00116807 0.96981352] : [0.]\n",
      "[0.9129539 0.0056415 0.0814046] : [0.]\n",
      "[0.61553445 0.00459638 0.37986917] : [0.]\n",
      "[0.92942615 0.00162241 0.06895144] : [0.]\n",
      "[9.05899980e-01 5.20649817e-04 9.35793702e-02] : [0.]\n",
      "[0.75816318 0.11076449 0.13107233] : [0.]\n",
      "[0.56947393 0.02732282 0.40320325] : [0.]\n",
      "[0.49695888 0.29786931 0.20517182] : [0.]\n",
      "[0.75712057 0.05349426 0.18938517] : [0.]\n",
      "[0.88955839 0.00762238 0.10281924] : [0.]\n",
      "[0.80982308 0.020913   0.16926393] : [0.]\n",
      "[0.82676814 0.01469431 0.15853755] : [0.]\n",
      "[0.87465068 0.00238387 0.12296545] : [0.]\n",
      "[0.25476003 0.00756822 0.73767175] : [0.]\n",
      "[9.24736976e-01 9.18339881e-04 7.43446840e-02] : [0.]\n",
      "[0.36275224 0.0372883  0.59995946] : [0.]\n",
      "[0.8445721  0.01796946 0.13745845] : [0.]\n",
      "[0.81137893 0.08012286 0.10849821] : [0.]\n",
      "[0.84221694 0.02604503 0.13173803] : [0.]\n",
      "[0.08131975 0.87045072 0.04822952] : [0.]\n",
      "[0.74606887 0.18721463 0.06671651] : [0.]\n",
      "[0.4075349 0.0493559 0.5431092] : [0.]\n",
      "[0.77810139 0.03944332 0.18245529] : [0.]\n",
      "[0.92571556 0.00803214 0.0662523 ] : [0.]\n",
      "[0.87879386 0.05781959 0.06338655] : [0.]\n",
      "[0.90490226 0.00994363 0.08515411] : [0.]\n",
      "[0.49950387 0.00313197 0.49736417] : [0.]\n",
      "[7.68141253e-01 5.21558182e-05 2.31806591e-01] : [0.]\n",
      "[0.8656525  0.07070107 0.06364643] : [0.]\n",
      "[0.42815778 0.305166   0.26667622] : [0.]\n",
      "[0.4294718  0.03185932 0.53866888] : [0.]\n",
      "[0.43766452 0.07157009 0.49076539] : [0.]\n",
      "[0.49293801 0.03555779 0.4715042 ] : [0.]\n",
      "[0.76282787 0.11662957 0.12054256] : [0.]\n",
      "[0.45271989 0.01012634 0.53715377] : [0.]\n",
      "[0.90971958 0.07559064 0.01468979] : [0.]\n",
      "[0.31296376 0.04221957 0.64481666] : [0.]\n",
      "[0.40573238 0.25873833 0.33552929] : [0.]\n",
      "[0.77091689 0.17032924 0.05875387] : [0.]\n",
      "[0.22071764 0.7086257  0.07065667] : [0.]\n",
      "[0.63677757 0.03073243 0.33249   ] : [0.]\n",
      "[0.80413255 0.13251152 0.06335593] : [0.]\n",
      "[0.15822945 0.00088798 0.84088257] : [0.]\n",
      "[0.91169256 0.04981433 0.03849312] : [0.]\n",
      "[0.56165444 0.07766552 0.36068004] : [0.]\n",
      "[3.08593920e-01 5.97422090e-04 6.90808657e-01] : [0.]\n",
      "[0.8698226  0.03733418 0.09284322] : [0.]\n",
      "[0.74368812 0.08115758 0.1751543 ] : [0.]\n",
      "[0.39056141 0.10723232 0.50220626] : [0.]\n",
      "[0.38274331 0.58300435 0.03425235] : [0.]\n",
      "[0.32645628 0.01317167 0.66037205] : [0.]\n",
      "[0.79035806 0.14954516 0.06009679] : [0.]\n",
      "[0.85194358 0.00666238 0.14139405] : [0.]\n",
      "[0.68889141 0.01883067 0.29227792] : [0.]\n",
      "[0.42128236 0.0317256  0.54699204] : [0.]\n",
      "[0.22374401 0.00431259 0.7719434 ] : [0.]\n",
      "[0.78833838 0.15485069 0.05681093] : [0.]\n",
      "[0.61977367 0.0031794  0.37704693] : [0.]\n",
      "[0.61955252 0.29845333 0.08199415] : [0.]\n",
      "[0.89291501 0.00729371 0.09979128] : [0.]\n",
      "[0.10744274 0.00411603 0.88844123] : [0.]\n",
      "[0.79240948 0.03348422 0.1741063 ] : [0.]\n",
      "[0.47143831 0.03843391 0.49012778] : [0.]\n",
      "[0.85418123 0.03482469 0.11099408] : [0.]\n",
      "[0.42165839 0.01743099 0.56091062] : [0.]\n",
      "[0.87650085 0.05059098 0.07290816] : [0.]\n",
      "[0.46604591 0.07354746 0.46040663] : [0.]\n",
      "[0.50016356 0.30961449 0.19022195] : [0.]\n",
      "[0.91873445 0.0037497  0.07751585] : [0.]\n",
      "[0.96256833 0.00841792 0.02901375] : [0.]\n",
      "[0.96705409 0.02103512 0.01191079] : [0.]\n",
      "[0.24557847 0.70007017 0.05435136] : [1.]\n",
      "[0.65480912 0.22147186 0.12371902] : [1.]\n",
      "[0.01450173 0.90457443 0.08092384] : [1.]\n",
      "[0.00660027 0.97070309 0.02269664] : [1.]\n",
      "[0.27775673 0.25629197 0.4659513 ] : [1.]\n",
      "[0.83854106 0.07137496 0.09008399] : [1.]\n",
      "[0.36986947 0.46914327 0.16098726] : [1.]\n",
      "[0.13711712 0.85804247 0.00484041] : [1.]\n",
      "[0.15739268 0.81843159 0.02417573] : [1.]\n",
      "[0.00372323 0.97124095 0.02503582] : [1.]\n",
      "[0.48401925 0.05340189 0.46257886] : [1.]\n",
      "[0.83048356 0.13477309 0.03474335] : [1.]\n",
      "[0.05321709 0.90697113 0.03981178] : [1.]\n",
      "[0.0257121  0.95060033 0.02368757] : [1.]\n",
      "[5.60555400e-04 9.98978137e-01 4.61307385e-04] : [1.]\n",
      "[2.37857891e-04 9.99409315e-01 3.52827468e-04] : [1.]\n",
      "[0.08806577 0.83918719 0.07274704] : [1.]\n",
      "[0.56579313 0.36058632 0.07362055] : [1.]\n",
      "[0.00374247 0.97290423 0.0233533 ] : [1.]\n",
      "[0.01183129 0.98092756 0.00724115] : [1.]\n",
      "[0.0711321  0.80619629 0.12267161] : [1.]\n",
      "[0.0088444  0.97671137 0.01444422] : [1.]\n",
      "[0.13924253 0.59894148 0.26181599] : [1.]\n",
      "[0.1071253  0.83678482 0.05608988] : [1.]\n",
      "[1.39265297e-03 9.97845555e-01 7.61791592e-04] : [1.]\n",
      "[3.29717519e-05 9.99670054e-01 2.96974639e-04] : [1.]\n",
      "[0.01540009 0.88607041 0.0985295 ] : [1.]\n",
      "[0.047556   0.94368245 0.00876155] : [1.]\n",
      "[2.36467061e-04 9.97685816e-01 2.07771682e-03] : [1.]\n",
      "[0.04183546 0.95349574 0.0046688 ] : [1.]\n",
      "[0.12180767 0.35432799 0.52386434] : [1.]\n",
      "[0.01313102 0.98051131 0.00635767] : [1.]\n",
      "[0.06227127 0.90973913 0.0279896 ] : [1.]\n",
      "[0.00902291 0.96183908 0.02913801] : [1.]\n",
      "[0.11200791 0.7435762  0.14441589] : [1.]\n",
      "[0.06826259 0.86919167 0.06254574] : [1.]\n",
      "[0.0497429  0.18275581 0.76750129] : [1.]\n",
      "[0.18994729 0.70194366 0.10810905] : [1.]\n",
      "[0.00618907 0.92925123 0.0645597 ] : [1.]\n",
      "[0.01547129 0.96649835 0.01803037] : [1.]\n",
      "[0.05361445 0.85894755 0.087438  ] : [1.]\n",
      "[1.23492984e-03 9.98091449e-01 6.73621391e-04] : [1.]\n",
      "[0.42573146 0.3812944  0.19297415] : [1.]\n",
      "[0.09988649 0.1044526  0.7956609 ] : [1.]\n",
      "[0.13289223 0.31728179 0.54982598] : [1.]\n",
      "[2.18255817e-04 9.99600721e-01 1.81023051e-04] : [1.]\n",
      "[0.81205005 0.09648048 0.09146947] : [1.]\n",
      "[4.67913024e-04 9.98834867e-01 6.97219775e-04] : [1.]\n",
      "[0.38100398 0.42264011 0.19635591] : [1.]\n",
      "[0.03160343 0.89152251 0.07687406] : [1.]\n",
      "[0.24239644 0.22991491 0.52768865] : [1.]\n",
      "[0.60480875 0.27360605 0.12158519] : [1.]\n",
      "[1.65211345e-04 9.99010465e-01 8.24323426e-04] : [1.]\n",
      "[1.39458944e-03 9.98270594e-01 3.34816425e-04] : [1.]\n",
      "[0.03130158 0.92079283 0.04790559] : [1.]\n",
      "[0.05077706 0.94262469 0.00659825] : [1.]\n",
      "[0.00514388 0.9887003  0.00615582] : [1.]\n",
      "[0.24591203 0.58319892 0.17088905] : [1.]\n",
      "[2.50055719e-03 9.96515711e-01 9.83731368e-04] : [1.]\n",
      "[0.04508727 0.35871533 0.5961974 ] : [1.]\n",
      "[0.01610806 0.96659713 0.01729481] : [1.]\n",
      "[0.66560263 0.15500551 0.17939185] : [1.]\n",
      "[0.60608104 0.12398479 0.26993417] : [1.]\n",
      "[0.00856559 0.97752038 0.01391404] : [1.]\n",
      "[0.19543039 0.56179339 0.24277623] : [1.]\n",
      "[0.05874469 0.91890208 0.02235322] : [1.]\n",
      "[0.22822765 0.70523061 0.06654174] : [1.]\n",
      "[0.35972224 0.59695773 0.04332003] : [1.]\n",
      "[0.72744656 0.09276809 0.17978535] : [1.]\n",
      "[0.00741303 0.98931175 0.00327522] : [1.]\n",
      "[3.35829508e-04 9.97660323e-01 2.00384745e-03] : [1.]\n",
      "[0.0501607  0.77111549 0.17872381] : [1.]\n",
      "[0.04781804 0.03788514 0.91429682] : [1.]\n",
      "[0.08272702 0.89384107 0.02343192] : [1.]\n",
      "[5.19125965e-04 9.92119474e-01 7.36140000e-03] : [1.]\n",
      "[0.03098396 0.96254414 0.00647189] : [1.]\n",
      "[0.02647366 0.86276091 0.11076543] : [1.]\n",
      "[0.01397952 0.98133363 0.00468685] : [1.]\n",
      "[0.44989769 0.37967109 0.17043122] : [1.]\n",
      "[0.56211298 0.30316951 0.13471752] : [1.]\n",
      "[0.4014888  0.01526706 0.58324414] : [1.]\n",
      "[0.49125137 0.2288618  0.27988682] : [1.]\n",
      "[0.6869628  0.21941351 0.09362369] : [1.]\n",
      "[2.72929304e-03 9.97096244e-01 1.74462982e-04] : [1.]\n",
      "[0.03884839 0.76311394 0.19803768] : [1.]\n",
      "[0.04202107 0.95283754 0.00514139] : [1.]\n",
      "[0.0041128  0.99477851 0.0011087 ] : [1.]\n",
      "[0.04997947 0.8297799  0.12024064] : [1.]\n",
      "[0.12311622 0.66102407 0.21585971] : [1.]\n",
      "[0.05217214 0.86347483 0.08435303] : [1.]\n",
      "[0.02342501 0.7450567  0.23151829] : [1.]\n",
      "[0.0655077  0.83842391 0.09606839] : [1.]\n",
      "[0.02231113 0.96392488 0.01376399] : [1.]\n",
      "[0.06310401 0.92502257 0.01187342] : [1.]\n",
      "[0.94890246 0.00403397 0.04706357] : [1.]\n",
      "[0.00348061 0.99496109 0.0015583 ] : [1.]\n",
      "[0.02141809 0.96340504 0.01517687] : [1.]\n",
      "[0.0372362  0.92955629 0.03320751] : [1.]\n",
      "[0.0988976  0.79375891 0.10734349] : [1.]\n",
      "[0.00437311 0.97677273 0.01885417] : [1.]\n",
      "[0.20303975 0.09732851 0.69963174] : [2.]\n",
      "[0.73772763 0.01753182 0.24474054] : [2.]\n",
      "[0.3781246  0.01472178 0.60715362] : [2.]\n",
      "[1.72952692e-01 4.37928495e-04 8.26609380e-01] : [2.]\n",
      "[0.19994741 0.00150372 0.79854887] : [2.]\n",
      "[0.62283312 0.00758302 0.36958386] : [2.]\n",
      "[0.05486734 0.00672124 0.93841141] : [2.]\n",
      "[0.76182136 0.09560334 0.1425753 ] : [2.]\n",
      "[0.01758682 0.89885783 0.08355535] : [2.]\n",
      "[0.51442984 0.0865794  0.39899076] : [2.]\n",
      "[0.16942642 0.00475328 0.82582031] : [2.]\n",
      "[0.07428978 0.00909298 0.91661724] : [2.]\n",
      "[0.1845553  0.61491788 0.20052682] : [2.]\n",
      "[0.43362794 0.0197667  0.54660536] : [2.]\n",
      "[0.68280654 0.04522458 0.27196888] : [2.]\n",
      "[0.41171606 0.07610188 0.51218205] : [2.]\n",
      "[0.46777996 0.02157241 0.51064763] : [2.]\n",
      "[0.08326638 0.00965296 0.90708065] : [2.]\n",
      "[0.82473188 0.09944018 0.07582794] : [2.]\n",
      "[0.52387002 0.00366499 0.47246499] : [2.]\n",
      "[0.32549039 0.00200752 0.67250209] : [2.]\n",
      "[0.10688596 0.00432737 0.88878666] : [2.]\n",
      "[0.02083614 0.12954451 0.84961934] : [2.]\n",
      "[0.52068701 0.008477   0.47083599] : [2.]\n",
      "[0.32876144 0.00356119 0.66767737] : [2.]\n",
      "[0.35350674 0.01760724 0.62888602] : [2.]\n",
      "[0.18492483 0.10745358 0.70762159] : [2.]\n",
      "[0.49297284 0.02189436 0.4851328 ] : [2.]\n",
      "[3.53533871e-01 1.23098908e-04 6.46343031e-01] : [2.]\n",
      "[0.33895829 0.22915372 0.43188799] : [2.]\n",
      "[0.1901563  0.68358678 0.12625693] : [2.]\n",
      "[0.11778743 0.00407864 0.87813393] : [2.]\n",
      "[5.83666300e-01 4.99020584e-04 4.15834679e-01] : [2.]\n",
      "[0.12230253 0.06966827 0.8080292 ] : [2.]\n",
      "[0.110035  0.0164793 0.8734857] : [2.]\n",
      "[0.15666296 0.25524161 0.58809544] : [2.]\n",
      "[0.2016934  0.01128223 0.78702437] : [2.]\n",
      "[0.27626282 0.20405049 0.51968669] : [2.]\n",
      "[0.1120401  0.38410019 0.50385971] : [2.]\n",
      "[0.52596714 0.00340789 0.47062496] : [2.]\n",
      "[0.13004526 0.15484584 0.7151089 ] : [2.]\n",
      "[8.33237636e-01 3.10930489e-04 1.66451433e-01] : [2.]\n",
      "[0.24182196 0.24091131 0.51726673] : [2.]\n",
      "[0.07683701 0.00122849 0.9219345 ] : [2.]\n",
      "[0.23944285 0.00225721 0.75829994] : [2.]\n",
      "[0.28599113 0.00964113 0.70436774] : [2.]\n",
      "[0.78573201 0.1059761  0.10829189] : [2.]\n",
      "[3.75270684e-02 3.60986592e-04 9.62111945e-01] : [2.]\n",
      "[0.04120466 0.82109026 0.13770508] : [2.]\n",
      "[0.05810978 0.06062913 0.88126109] : [2.]\n",
      "[1.42277350e-01 1.11863381e-04 8.57610787e-01] : [2.]\n",
      "[0.73850622 0.05533389 0.20615988] : [2.]\n",
      "[0.01626991 0.01584933 0.96788076] : [2.]\n",
      "[0.30113123 0.00204277 0.696826  ] : [2.]\n",
      "[0.15154884 0.40635537 0.44209579] : [2.]\n",
      "[0.72508196 0.00148984 0.2734282 ] : [2.]\n",
      "[0.06841658 0.00209924 0.92948419] : [2.]\n",
      "[0.14488176 0.01591083 0.83920741] : [2.]\n",
      "[0.00516601 0.08004284 0.91479115] : [2.]\n",
      "[0.01813393 0.94656974 0.03529633] : [2.]\n",
      "[0.55424011 0.0019691  0.44379079] : [2.]\n",
      "[6.10970664e-02 3.82925012e-05 9.38864641e-01] : [2.]\n",
      "[0.43584783 0.29913774 0.26501443] : [2.]\n",
      "[0.23579032 0.70268491 0.06152477] : [2.]\n",
      "[0.09149114 0.00521486 0.903294  ] : [2.]\n",
      "[0.00729148 0.02252665 0.97018188] : [2.]\n",
      "[0.31290315 0.3035291  0.38356775] : [2.]\n",
      "[0.15097238 0.04079353 0.80823409] : [2.]\n",
      "[0.04703342 0.02675835 0.92620823] : [2.]\n",
      "[0.67434002 0.0097505  0.31590948] : [2.]\n",
      "[0.31882991 0.29923094 0.38193915] : [2.]\n",
      "[5.08382549e-01 2.52257937e-04 4.91365193e-01] : [2.]\n",
      "[0.12278793 0.00395432 0.87325775] : [2.]\n",
      "[0.16743307 0.08747792 0.745089  ] : [2.]\n",
      "[0.18562359 0.00627065 0.80810576] : [2.]\n",
      "[0.09426202 0.21047152 0.69526646] : [2.]\n",
      "[0.11286344 0.02325129 0.86388527] : [2.]\n",
      "[0.69329286 0.04224299 0.26446415] : [2.]\n",
      "[0.0984157  0.64701425 0.25457005] : [2.]\n",
      "[0.14899881 0.15748647 0.69351472] : [2.]\n",
      "[0.04079807 0.26979241 0.68940953] : [2.]\n",
      "[0.36045126 0.22972173 0.40982701] : [2.]\n",
      "[0.27594615 0.00460228 0.71945157] : [2.]\n",
      "[0.44605151 0.00174975 0.55219875] : [2.]\n",
      "[0.12404614 0.07891197 0.7970419 ] : [2.]\n",
      "[0.22861599 0.01958213 0.75180188] : [2.]\n",
      "[0.06844592 0.00211576 0.92943832] : [2.]\n",
      "[0.39904901 0.00596741 0.59498358] : [2.]\n",
      "[1.88458611e-01 6.60705557e-04 8.10880684e-01] : [2.]\n",
      "[0.31401572 0.0053861  0.68059818] : [2.]\n",
      "[0.14412976 0.10580105 0.75006919] : [2.]\n",
      "[5.99563320e-01 2.68292448e-04 4.00168387e-01] : [2.]\n",
      "[0.536884   0.00137332 0.46174269] : [2.]\n",
      "[0.56989304 0.07569528 0.35441168] : [2.]\n",
      "[0.05780294 0.01354838 0.92864869] : [2.]\n",
      "[0.21959909 0.00362535 0.77677556] : [2.]\n",
      "[0.08146716 0.00192981 0.91660302] : [2.]\n",
      "[0.04517609 0.86567854 0.08914537] : [2.]\n",
      "[0.4812678  0.01279301 0.50593919] : [2.]\n",
      "[0.54142228 0.02549166 0.43308606] : [2.]\n",
      "\n",
      " [ 予測結果 ]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.65      0.73      0.69       100\n",
      "         1.0       0.84      0.75      0.79       100\n",
      "         2.0       0.69      0.68      0.69       100\n",
      "\n",
      "    accuracy                           0.72       300\n",
      "   macro avg       0.73      0.72      0.72       300\n",
      "weighted avg       0.73      0.72      0.72       300\n",
      "\n",
      "\n",
      " [ 混同行列 ]\n",
      "[[73  6 21]\n",
      " [16 75  9]\n",
      " [24  8 68]]\n"
     ]
    }
   ],
   "source": [
    "#!/usr/local/bin python3.7\n",
    "import sys\n",
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix, precision_score, recall_score, f1_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import numpy as np\n",
    "\n",
    "#===============================================================================================================================================\n",
    "\n",
    "# 学習データのロード\n",
    "data_learn = np.loadtxt(\n",
    "    fname=\"prac_1_train-1.csv\",\n",
    "    dtype=\"float\",\n",
    "    delimiter=\",\")\n",
    "\n",
    "# 学習データの特徴量（4次元）\n",
    "train_data = data_learn[:, 0:4]\n",
    "\n",
    "# 学習データの目的変数( malignant, benign )\n",
    "train_label = data_learn[:, 4:5]\n",
    "\n",
    "#===============================================================================================================================================\n",
    "\n",
    "# テストデータのロード\n",
    "data_test = np.loadtxt(\n",
    "    fname=\"prac_1_test-1.csv\",\n",
    "    dtype=\"float\",\n",
    "    delimiter=\",\")\n",
    "\n",
    "# テストデータの特徴量（4次元）\n",
    "test_data = data_test[:, 0:4]\n",
    "\n",
    "# テストデータの目的変数( malignant, benign )\n",
    "test_label = data_test[:, 4:5]\n",
    "\n",
    "#===============================================================================================================================================\n",
    "\n",
    "# ロジスティック回帰\n",
    "model = LogisticRegression(C=1.0,penalty='l2',solver='lbfgs',max_iter=100)\n",
    "\n",
    "# 学習\n",
    "model.fit(train_data, train_label)\n",
    "\n",
    "# 予測\n",
    "predict = model.predict(test_data)\n",
    "\n",
    "# 係数と切片\n",
    "print( '\\n 係数ベクトル : ' , model.coef_ )\n",
    "print( ' 切片 : ' , model.intercept_)\n",
    "\n",
    "# 予測値，教師ラベル\n",
    "print( '\\n [ 予測値  :  教師ラベル ]' )\n",
    "predict_proba = model.predict_proba(test_data)\n",
    "for i in range(len(test_label)):\n",
    "    print( predict_proba[i] , ':' , test_label[i] )\n",
    "    \n",
    "\n",
    "# 予測結果の表示\n",
    "\"\"\"\n",
    "print( \"\\n [ 予測結果 ]\" )\n",
    "print( ' accuracy  : ' , accuracy_score(test_label, predict) )\n",
    "print( ' precision : ' , precision_score(test_label, predict) )\n",
    "print( ' recall    : ' , recall_score(test_label, predict) )\n",
    "print( ' f1-score  : ' , f1_score(test_label, predict) )\n",
    "\"\"\"\n",
    "\n",
    "print( \"\\n [ 予測結果 ]\" )\n",
    "print( classification_report(test_label, predict) )\n",
    "\n",
    "print( \"\\n [ 混同行列 ]\" )\n",
    "print( confusion_matrix(test_label, predict) )"
   ]
  },
  {
   "source": [
    "# 10/21 最近傍法\n",
    "k近傍法のプログラム\n",
    "数字認識(digitsデータベース)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "出力形式は\n第1候補(ラベル) ，第2候補(ラベル)，..., 第k候補(ラベル)  [それぞれの候補との距離]\n-> 予測値 (正解データ)\nのようになっています．\n 660(0)  805(0)  164(0)  268(0)  709(0)  [ 16.40 17.00 20.40 20.42 20.93  ] -> 0 [ 0 ]\n 727(0)  208(0)  231(0)  103(0)  596(0)  [ 16.73 18.14 19.05 22.18 22.29  ] -> 0 [ 0 ]\n 265(4)  250(4)  329(4)   50(4)  653(4)  [ 14.59 19.60 19.67 20.78 21.40  ] -> 4 [ 4 ]\n 488(6)  827(6)  605(6)  518(6)  307(6)  [ 14.32 14.80 16.67 16.82 17.06  ] -> 6 [ 6 ]\n 101(5)  869(5)  804(5)  587(5)  135(5)  [ 26.44 27.42 30.23 31.94 33.18  ] -> 5 [ 5 ]\n 698(6)   20(6)  160(6)  509(6)  789(6)  [ 14.35 15.26 16.00 16.28 16.40  ] -> 6 [ 6 ]\n 239(9)  380(9)  362(9)  471(1)  694(1)  [ 22.49 29.22 30.22 30.72 31.98  ] -> 9 [ 9 ]\n 869(5)  135(5)  804(5)  101(5)  127(5)  [ 14.97 20.22 20.40 22.07 22.83  ] -> 5 [ 5 ]\n 754(7)  238(7)  813(7)  442(7)  726(7)  [ 21.70 23.73 27.71 29.82 30.03  ] -> 7 [ 7 ]\n 819(4)  378(4)  888(4)  457(4)   78(4)  [ 17.49 17.80 18.03 19.42 20.20  ] -> 4 [ 4 ]\n  17(5)  192(5)  799(5)  366(5)  272(5)  [ 16.31 18.41 19.34 22.23 23.02  ] -> 5 [ 5 ]\n 886(7)  420(7)  501(7)  277(7)  683(7)  [ 15.07 17.69 17.92 17.97 19.39  ] -> 7 [ 7 ]\n 251(1)  341(6)  247(6)  617(6)  222(6)  [ 19.52 19.90 21.91 22.02 22.14  ] -> 6 [ 6 ]\n  46(5)  322(5)  686(5)  152(5)  649(5)  [ 15.68 18.89 19.54 20.22 20.42  ] -> 5 [ 5 ]\n  97(5)  464(5)  121(5)  322(5)  470(5)  [ 22.98 25.22 26.46 26.76 27.31  ] -> 5 [ 5 ]\n 404(2)  837(2)  719(2)   45(2)  394(2)  [ 16.40 16.82 24.06 26.44 27.89  ] -> 2 [ 2 ]\n 735(5)   71(5)  847(5)  322(5)  686(5)  [ 20.54 21.07 22.65 22.69 23.79  ] -> 5 [ 5 ]\n 886(7)  194(7)   28(7)  316(7)  666(7)  [ 10.95 13.38 15.49 15.75 16.70  ] -> 7 [ 7 ]\n 257(0)  229(0)  821(0)  290(0)  596(0)  [ 11.79 12.25 12.37 12.73 13.11  ] -> 0 [ 0 ]\n 163(4)  670(4)   41(4)  773(4)  265(4)  [ 14.04 14.04 18.36 20.22 22.93  ] -> 4 [ 4 ]\n 746(2)  567(2)  211(2)  429(2)  860(2)  [ 26.19 27.18 28.21 29.56 32.22  ] -> 2 [ 2 ]\n 869(5)  101(5)  506(5)  587(5)  804(5)  [ 17.06 19.85 21.95 22.69 23.04  ] -> 5 [ 5 ]\n 131(9)   14(9)   61(9)  387(9)  460(9)  [ 26.94 32.92 33.78 33.78 34.06  ] -> 9 [ 9 ]\n 446(3)  108(3)  589(3)   15(3)  822(3)  [ 18.47 21.47 21.70 21.82 22.85  ] -> 3 [ 3 ]\n 293(1)  256(1)  485(1)   16(1)  333(1)  [ 14.76 20.86 20.95 21.63 22.74  ] -> 1 [ 1 ]\n 183(3)  808(3)   84(3)  493(3)  447(3)  [ 17.89 18.14 19.87 21.19 21.26  ] -> 3 [ 3 ]\n 728(6)  558(6)  854(6)   80(6)  388(6)  [ 19.92 20.47 20.78 21.70 22.58  ] -> 6 [ 6 ]\n 254(4)  279(4)  888(4)  457(4)  342(4)  [ 17.09 17.18 18.52 18.68 18.87  ] -> 4 [ 4 ]\n  66(4)  321(4)  611(4)  219(4)  329(4)  [ 20.66 21.31 24.92 26.57 26.91  ] -> 4 [ 4 ]\n 802(1)  496(1)  166(1)  542(1)  139(1)  [ 14.11 18.03 19.44 25.32 26.46  ] -> 1 [ 1 ]\n 596(0)  156(0)  229(0)  571(0)  170(0)  [ 10.95 14.70 14.83 14.97 15.20  ] -> 0 [ 0 ]\n 384(0)  502(0)  534(0)  571(0)  229(0)  [ 19.54 20.47 21.10 21.33 21.66  ] -> 0 [ 0 ]\n 163(4)  138(4)  670(4)   65(4)   41(4)  [ 13.82 19.82 20.12 20.98 21.42  ] -> 4 [ 4 ]\n 605(6)  681(6)  699(6)  628(6)   98(6)  [ 14.18 14.49 14.66 15.84 15.87  ] -> 6 [ 6 ]\n 749(1)   58(1)  865(1)  282(1)  434(1)  [  9.11 11.36 12.04 13.86 14.04  ] -> 1 [ 1 ]\n 719(2)  575(2)  844(2)  394(2)  835(2)  [ 22.09 22.11 23.32 23.64 24.41  ] -> 2 [ 2 ]\n 535(7)  197(7)  813(7)  836(7)  145(7)  [ 20.00 22.78 23.39 23.58 25.40  ] -> 7 [ 7 ]\n  65(4)   50(4)  265(4)   78(4)  653(4)  [ 16.73 18.30 18.71 19.24 19.62  ] -> 4 [ 4 ]\n 700(2)  838(2)  207(2)  626(2)  430(2)  [ 28.39 28.72 28.95 34.51 34.73  ] -> 2 [ 2 ]\n 409(4)  201(4)  892(1)  682(4)  216(4)  [ 18.57 23.81 24.49 24.80 28.44  ] -> 4 [ 4 ]\n 845(5)  587(5)   97(5)  759(5)  470(5)  [ 17.78 20.59 21.82 25.85 27.50  ] -> 5 [ 5 ]\n  21(4)  541(4)  222(6)  744(4)  453(6)  [ 21.59 23.30 25.40 25.63 26.68  ] -> 4 [ 4 ]\n 788(2)  837(2)  404(2)  456(2)   69(2)  [ 28.98 29.10 29.34 30.17 30.43  ] -> 2 [ 2 ]\n 674(0)  717(0)  821(0)  640(0)  765(0)  [ 13.23 17.69 18.00 18.57 18.79  ] -> 0 [ 0 ]\n 387(9)  337(9)  320(9)  624(9)  294(9)  [ 18.38 19.72 21.86 22.83 22.89  ] -> 9 [ 9 ]\n 707(3)  604(3)  839(3)  855(3)   15(3)  [ 13.45 16.52 17.61 17.69 18.89  ] -> 3 [ 3 ]\n 607(0)  812(0)  564(0)  257(0)  745(0)  [ 12.17 14.28 14.87 15.68 17.64  ] -> 0 [ 0 ]\n 278(7)  644(7)  368(7)  423(7)  288(7)  [ 19.26 23.28 23.32 28.44 28.51  ] -> 7 [ 7 ]\n 260(5)  847(5)  113(5)  171(5)  495(5)  [ 13.15 16.28 19.26 20.45 20.52  ] -> 5 [ 5 ]\n 322(5)  121(5)  462(5)  464(5)  470(5)  [ 23.49 26.38 26.63 27.20 28.53  ] -> 5 [ 5 ]\n\n [ 予測結果 ]\n              precision    recall  f1-score   support\n\n           0       1.00      1.00      1.00        85\n           1       0.90      1.00      0.95        90\n           2       0.99      0.99      0.99       100\n           3       0.97      0.94      0.95        95\n           4       0.99      0.99      0.99        92\n           5       0.96      1.00      0.98        92\n           6       1.00      1.00      1.00        84\n           7       0.96      1.00      0.98        80\n           8       0.96      0.89      0.92        90\n           9       0.99      0.91      0.95        91\n\n    accuracy                           0.97       899\n   macro avg       0.97      0.97      0.97       899\nweighted avg       0.97      0.97      0.97       899\n\n\n [ 正解率 ]\n0.9710789766407119\n\n [ 混同行列 ]\n[[85  0  0  0  0  0  0  0  0  0]\n [ 0 90  0  0  0  0  0  0  0  0]\n [ 0  0 99  0  0  0  0  1  0  0]\n [ 0  0  1 89  0  1  0  1  3  0]\n [ 0  0  0  0 91  0  0  1  0  0]\n [ 0  0  0  0  0 92  0  0  0  0]\n [ 0  0  0  0  0  0 84  0  0  0]\n [ 0  0  0  0  0  0  0 80  0  0]\n [ 0  8  0  1  0  0  0  0 80  1]\n [ 0  2  0  2  1  3  0  0  0 83]]\n"
     ]
    }
   ],
   "source": [
    "# k近傍法（digitsデータベース）\n",
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "\n",
    "# k近傍法\n",
    "K = 5\n",
    "\n",
    "# データのロード\n",
    "# 'data' , 'target' , 'frame' , 'future_names' , 'target_names' , 'images' , 'DESCR' からなる1797個のデータ\n",
    "digits = datasets.load_digits()\n",
    "\n",
    "# 特徴量 (1797, 8, 8) \n",
    "# 縦横8*8の画像データを長さ64の特徴量ベクトルに変換(np.reshape)\n",
    "image = digits.images\n",
    "total , x_size , y_size = image.shape \n",
    "image = np.reshape( image , [total,x_size*y_size] )\n",
    "\n",
    "# 目的変数\n",
    "label = digits.target\n",
    "\n",
    "# 学習データ，テストデータ(ホールドアウト法)\n",
    "train_data, test_data, train_label, test_label = train_test_split(image, label, test_size=0.5, random_state=None)\n",
    "\n",
    "# 引数の中身：(調べる近傍の個数，アルゴリズム，計量，ミンコフスキー距離のp)\n",
    "# algorithm：デフォルトでは'brute' → 全探索(デフォルト)\n",
    "# metric：デフォルトではp=2のユークリッド距離\n",
    "model = KNeighborsClassifier(n_neighbors=K, algorithm='kd_tree', metric='minkowski', p=2)\n",
    "# k = 4で簡単に使いたい場合下の行のようになる\n",
    "# model = KNeighborsClassifier(n_neighbors=4)\n",
    "\n",
    "# 学習\n",
    "model.fit(train_data, train_label)\n",
    "\n",
    "# 予測\n",
    "predict = model.predict(test_data)\n",
    "distance , result = model.kneighbors(test_data,n_neighbors=K)\n",
    "\n",
    "# K個の候補，距離，予測結果，正解の表示\n",
    "#for i in range(len(test_data)): # 全て表示していない\n",
    "print(\"出力形式は\")\n",
    "print(\"第1候補(ラベル) ，第2候補(ラベル)，..., 第k候補(ラベル)  [それぞれの候補との距離]\")\n",
    "print(\"-> 予測値 (正解データ)\")\n",
    "print(\"のようになっています．\")\n",
    "for i in range(50):\n",
    "    for j in range( K ):\n",
    "        print( \"{0:4d}({1})\".format(result[i,j],train_label[ result[i,j] ]) , end=\" \")\n",
    "    print( \" [ \" , end=\"\" )\n",
    "    for j in range( K ):\n",
    "        print( \"{0:5.2f}\".format( distance[i,j] ) , end=\" \")\n",
    "    print( \" ] -> {0} [ {1} ]\".format( predict[i] , test_label[i] ) )\n",
    "\n",
    "print( \"\\n [ 予測結果 ]\" )\n",
    "print( classification_report(test_label, predict) )\n",
    "\n",
    "print( \"\\n [ 正解率 ]\" )\n",
    "print( accuracy_score(test_label, predict) )\n",
    "\n",
    "print( \"\\n [ 混同行列 ]\" )\n",
    "print( confusion_matrix(test_label, predict) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データのロード\n",
    "digits = datasets.load_digits()\n",
    "image = digits.images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'data': array([[ 0.,  0.,  5., ...,  0.,  0.,  0.],\n       [ 0.,  0.,  0., ..., 10.,  0.,  0.],\n       [ 0.,  0.,  0., ..., 16.,  9.,  0.],\n       ...,\n       [ 0.,  0.,  1., ...,  6.,  0.,  0.],\n       [ 0.,  0.,  2., ..., 12.,  0.,  0.],\n       [ 0.,  0., 10., ..., 12.,  1.,  0.]]), 'target': array([0, 1, 2, ..., 8, 9, 8]), 'frame': None, 'feature_names': ['pixel_0_0', 'pixel_0_1', 'pixel_0_2', 'pixel_0_3', 'pixel_0_4', 'pixel_0_5', 'pixel_0_6', 'pixel_0_7', 'pixel_1_0', 'pixel_1_1', 'pixel_1_2', 'pixel_1_3', 'pixel_1_4', 'pixel_1_5', 'pixel_1_6', 'pixel_1_7', 'pixel_2_0', 'pixel_2_1', 'pixel_2_2', 'pixel_2_3', 'pixel_2_4', 'pixel_2_5', 'pixel_2_6', 'pixel_2_7', 'pixel_3_0', 'pixel_3_1', 'pixel_3_2', 'pixel_3_3', 'pixel_3_4', 'pixel_3_5', 'pixel_3_6', 'pixel_3_7', 'pixel_4_0', 'pixel_4_1', 'pixel_4_2', 'pixel_4_3', 'pixel_4_4', 'pixel_4_5', 'pixel_4_6', 'pixel_4_7', 'pixel_5_0', 'pixel_5_1', 'pixel_5_2', 'pixel_5_3', 'pixel_5_4', 'pixel_5_5', 'pixel_5_6', 'pixel_5_7', 'pixel_6_0', 'pixel_6_1', 'pixel_6_2', 'pixel_6_3', 'pixel_6_4', 'pixel_6_5', 'pixel_6_6', 'pixel_6_7', 'pixel_7_0', 'pixel_7_1', 'pixel_7_2', 'pixel_7_3', 'pixel_7_4', 'pixel_7_5', 'pixel_7_6', 'pixel_7_7'], 'target_names': array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), 'images': array([[[ 0.,  0.,  5., ...,  1.,  0.,  0.],\n        [ 0.,  0., 13., ..., 15.,  5.,  0.],\n        [ 0.,  3., 15., ..., 11.,  8.,  0.],\n        ...,\n        [ 0.,  4., 11., ..., 12.,  7.,  0.],\n        [ 0.,  2., 14., ..., 12.,  0.,  0.],\n        [ 0.,  0.,  6., ...,  0.,  0.,  0.]],\n\n       [[ 0.,  0.,  0., ...,  5.,  0.,  0.],\n        [ 0.,  0.,  0., ...,  9.,  0.,  0.],\n        [ 0.,  0.,  3., ...,  6.,  0.,  0.],\n        ...,\n        [ 0.,  0.,  1., ...,  6.,  0.,  0.],\n        [ 0.,  0.,  1., ...,  6.,  0.,  0.],\n        [ 0.,  0.,  0., ..., 10.,  0.,  0.]],\n\n       [[ 0.,  0.,  0., ..., 12.,  0.,  0.],\n        [ 0.,  0.,  3., ..., 14.,  0.,  0.],\n        [ 0.,  0.,  8., ..., 16.,  0.,  0.],\n        ...,\n        [ 0.,  9., 16., ...,  0.,  0.,  0.],\n        [ 0.,  3., 13., ..., 11.,  5.,  0.],\n        [ 0.,  0.,  0., ..., 16.,  9.,  0.]],\n\n       ...,\n\n       [[ 0.,  0.,  1., ...,  1.,  0.,  0.],\n        [ 0.,  0., 13., ...,  2.,  1.,  0.],\n        [ 0.,  0., 16., ..., 16.,  5.,  0.],\n        ...,\n        [ 0.,  0., 16., ..., 15.,  0.,  0.],\n        [ 0.,  0., 15., ..., 16.,  0.,  0.],\n        [ 0.,  0.,  2., ...,  6.,  0.,  0.]],\n\n       [[ 0.,  0.,  2., ...,  0.,  0.,  0.],\n        [ 0.,  0., 14., ..., 15.,  1.,  0.],\n        [ 0.,  4., 16., ..., 16.,  7.,  0.],\n        ...,\n        [ 0.,  0.,  0., ..., 16.,  2.,  0.],\n        [ 0.,  0.,  4., ..., 16.,  2.,  0.],\n        [ 0.,  0.,  5., ..., 12.,  0.,  0.]],\n\n       [[ 0.,  0., 10., ...,  1.,  0.,  0.],\n        [ 0.,  2., 16., ...,  1.,  0.,  0.],\n        [ 0.,  0., 15., ..., 15.,  0.,  0.],\n        ...,\n        [ 0.,  4., 16., ..., 16.,  6.,  0.],\n        [ 0.,  8., 16., ..., 16.,  8.,  0.],\n        [ 0.,  1.,  8., ..., 12.,  1.,  0.]]]), 'DESCR': \".. _digits_dataset:\\n\\nOptical recognition of handwritten digits dataset\\n--------------------------------------------------\\n\\n**Data Set Characteristics:**\\n\\n    :Number of Instances: 5620\\n    :Number of Attributes: 64\\n    :Attribute Information: 8x8 image of integer pixels in the range 0..16.\\n    :Missing Attribute Values: None\\n    :Creator: E. Alpaydin (alpaydin '@' boun.edu.tr)\\n    :Date: July; 1998\\n\\nThis is a copy of the test set of the UCI ML hand-written digits datasets\\nhttps://archive.ics.uci.edu/ml/datasets/Optical+Recognition+of+Handwritten+Digits\\n\\nThe data set contains images of hand-written digits: 10 classes where\\neach class refers to a digit.\\n\\nPreprocessing programs made available by NIST were used to extract\\nnormalized bitmaps of handwritten digits from a preprinted form. From a\\ntotal of 43 people, 30 contributed to the training set and different 13\\nto the test set. 32x32 bitmaps are divided into nonoverlapping blocks of\\n4x4 and the number of on pixels are counted in each block. This generates\\nan input matrix of 8x8 where each element is an integer in the range\\n0..16. This reduces dimensionality and gives invariance to small\\ndistortions.\\n\\nFor info on NIST preprocessing routines, see M. D. Garris, J. L. Blue, G.\\nT. Candela, D. L. Dimmick, J. Geist, P. J. Grother, S. A. Janet, and C.\\nL. Wilson, NIST Form-Based Handprint Recognition System, NISTIR 5469,\\n1994.\\n\\n.. topic:: References\\n\\n  - C. Kaynak (1995) Methods of Combining Multiple Classifiers and Their\\n    Applications to Handwritten Digit Recognition, MSc Thesis, Institute of\\n    Graduate Studies in Science and Engineering, Bogazici University.\\n  - E. Alpaydin, C. Kaynak (1998) Cascading Classifiers, Kybernetika.\\n  - Ken Tang and Ponnuthurai N. Suganthan and Xi Yao and A. Kai Qin.\\n    Linear dimensionalityreduction using relevance weighted LDA. School of\\n    Electrical and Electronic Engineering Nanyang Technological University.\\n    2005.\\n  - Claudio Gentile. A New Approximate Maximal Margin Classification\\n    Algorithm. NIPS. 2000.\"}\n1797\n1797\n"
     ]
    }
   ],
   "source": [
    "print(digits)\n",
    "print(len(digits[\"data\"]))\n",
    "print(len(image))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'data' , 'target' , 'frame' , 'future_names' , 'target_names' , 'images' , 'DESCR' からなるデータ"
   ]
  }
 ]
}